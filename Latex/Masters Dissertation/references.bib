@inproceedings{sample_key,
  author    = {Cockrum, R. and Clark, D. and Mylona, Z.},
  booktitle = {FIE'99 Frontiers in Education. 29th Annual Frontiers in Education Conference. Designing the Future of Science and Engineering Education. Conference Proceedings (IEEE Cat. No.99CH37011},
  title     = {Motivating engineering students to write technical papers},
  year      = {1999},
  volume    = {3},
  doi       = {10.1109/FIE.1999.840386}
}

@article{bartolo2024integrating,
  title={Integrating Saliency Ranking and Reinforcement Learning for Enhanced Object Detection},
  author={Bartolo, Matthias and Seychell, Dylan and Bajada, Josef},
  journal={arXiv preprint arXiv:2408.06803},
  year={2024}
}

% ------------------------------ Applications ----------------------------------
@article{applications,
author = {Challa, Narayana},
year = {2023},
month = {12},
pages = {121-133},
title = {Artificial Intelligence for Object Detection and its Metadata},
volume = {2},
doi = {10.17605/OSF.IO/FG3SQ}
}

@article{application_visual_scene1,
author = {Kumar, Kapil and Verma, Kamal},
year = {2023},
month = {11},
pages = {045-050},
title = {Comparative study on object detection in visual scenes using deep learning},
volume = {10},
journal = {World Journal of Advanced Engineering Technology and Sciences},
doi = {10.30574/wjaets.2023.10.2.0262}
}

@article{application_visual_scene2,
author = {Achirei, Stefan},
year = {2021},
month = {09},
pages = {57-72},
title = {Short Literature Review for Visual Scene Understanding},
volume = {67},
journal = {Bulletin of the Polytechnic Institute of Iași. Electrical Engineering, Power Engineering, Electronics Section},
doi = {10.2478/bipie-2021-0017}
}

@article{application_environment1,
  author       = {Li, S. and Zhang, H. and Xu, F.},
  title        = {Intelligent Detection Method for Wildlife Based on Deep Learning},
  journal      = {Sensors (Basel)},
  volume       = {23},
  number       = {24},
  pages        = {9669},
  year         = {2023},
  month        = {12},
  doi          = {10.3390/s23249669},
  PMID         = {38139515},
  PMCID        = {PMC10747703}
}

@article{application_environment2,
title = {WilDect-YOLO: An efficient and robust computer vision-based accurate object localization model for automated endangered wildlife detection},
journal = {Ecological Informatics},
volume = {75},
pages = {101919},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2022.101919},
author = {Arunabha M. Roy and Jayabrata Bhaduri and Teerath Kumar and Kislay Raj},
keywords = {Endangered wildlife detection, You only look once (YOLOv4) algorithm, Object detection (OD), Computer vision, Deep learning (DL), Wildlife preservation},
}

@article{application_uav,
author = {Jain, Ayush and R., Rohit and Narang, Pratik and Mandal, Murari and Chamola, Vinay and Yu, F and Guizani, Mohsen},
year = {2021},
month = {03},
pages = {},
title = {AI-Enabled Object Detection in UAVs: Challenges, Design Choices, and Research Directions},
volume = {35},
journal = {IEEE Network},
doi = {10.1109/MNET.011.2000643}
}

@inproceedings{application_obstacles,
  author={Lagisetty, R. and Philip, N. K. and Padhi, R. and Bhat, M. S.},
  booktitle={2013 IEEE International Conference on Control Applications (CCA)}, 
  title={Object detection and obstacle avoidance for mobile robot using stereo camera}, 
  year={2013},
  volume={},
  number={},
  pages={605-610},
  keywords={Cameras;Collision avoidance;Three-dimensional displays;Mobile robots;Estimation;Navigation;Obstacle detection and avoidance;Stereo vision;Potential field},
  doi={10.1109/CCA.2013.6662816}
}

@INPROCEEDINGS{application_med1,
  author={Micallef, Neil and Debono, Carl James and Seychell, Dylan and Attard, Conrad},
  booktitle={2022 IEEE 21st Mediterranean Electrotechnical Conference (MELECON)}, 
  title={Automatic Detection of COVID-19 Pneumonia in Chest Computed Tomography Scans Using Convolutional Neural Networks}, 
  year={2022},
  volume={},
  number={},
  pages={1118-1123},
  keywords={COVID-19;Training;Visualization;Computed tomography;Pulmonary diseases;Computational modeling;Convolutional neural networks;COVID-19;Coronavirus;computed tomography;deep learning},
  doi={10.1109/MELECON53508.2022.9843100}}


@article{application_med2,
author = {Micallef, Neil and Seychell, Dylan and Bajada, Claude},
year = {2021},
month = {09},
pages = {1-1},
title = {Exploring the U-Net++ Model for Automatic Brain Tumor Segmentation},
volume = {PP},
journal = {IEEE Access},
doi = {10.1109/ACCESS.2021.3111131}
}

@inproceedings{application_entertainment1,
author = {Chung, Jaeyong and Kim, Jin Ryong and Shim, Kwanghyun},
year = {2005},
month = {12},
pages = {1 - 6},
title = {Vision Based Motion Tracking System for Interactive Entertainment Applications},
volume = {2007},
doi = {10.1109/TENCON.2005.300942}
}

@article{application_entertainment2,
  title={A study on recognizing multi-real world object and estimating 3D position in augmented reality},
  author={Lee, Taehee and Jung, Chanyoung and Lee, Kyungeun and et al.},
  journal={Journal of Supercomputing},
  volume={78},
  pages={7509--7528},
  year={2022},
  publisher={Springer},
  doi={10.1007/s11227-021-04161-0}
}

@misc{pilz2024increasedcomputeefficiencydiffusion,
      title={Increased Compute Efficiency and the Diffusion of AI Capabilities}, 
      author={Konstantin Pilz and Lennart Heim and Nicholas Brown},
      year={2024},
      eprint={2311.15377},
      archivePrefix={arXiv},
      primaryClass={cs.CY},
}

@article{application_automation1,
author = {Abdul-Khalil, Syamimi and Rahman, Shuzlina and Mutalib, Sofianita and Kamarudin, Saidatul and Kamaruddin, Siti},
year = {2023},
month = {09},
pages = {1033},
title = {A review on object detection for autonomous mobile robot},
volume = {12},
journal = {IAES International Journal of Artificial Intelligence (IJ-AI)},
doi = {10.11591/ijai.v12.i3.pp1033-1043}
}

@article{application_automation2,
author = {Martínez, Ester and del Pobil, Angel P.},
year = {2017},
month = {03},
pages = {1-1},
title = {Object Detection and Recognition for Assistive Robots},
volume = {PP},
journal = {IEEE Robotics \& Automation Magazine},
doi = {10.1109/MRA.2016.2615329}
}

% -------------- Object Detection Problem

@INPROCEEDINGS{od_1,
  author={Harzallah, Hedi and Jurie, Frédéric and Schmid, Cordelia},
  booktitle={2009 IEEE 12th International Conference on Computer Vision}, 
  title={Combining efficient object localization and image classification}, 
  year={2009},
  volume={},
  number={},
  pages={237-244},
  keywords={Image classification;Object detection;Detectors;Image segmentation;Support vector machines;Support vector machine classification;Layout;Robustness;Machine learning algorithms;Machine learning},
  doi={10.1109/ICCV.2009.5459257}}

@inproceedings{od_3,
author = {Alhardi, Anas and Afeef, Mustafa},
year = {2024},
month = {03},
pages = {391-399},
title = {Object Detection Algorithms \& Techniques},
isbn = {978-625-6530-93-5},
booktitle={}
}

@article{survey_od_problem,
title = {Development and challenges of object detection: A survey},
journal = {Neurocomputing},
volume = {598},
pages = {128102},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.128102},
author = {Zonghui Li and Yongsheng Dong and Longchao Shen and Yafeng Liu and Yuanhua Pei and Haotian Yang and Lintao Zheng and Jinwen Ma},
keywords = {Object detection, Deep learning, Datasets, Evaluation metrics, Difficulties and challenges},
abstract = {Object detection is a basic vision task that accompanies people’s daily lives all the time. The development of object detection technology has experienced an evolution from traditional-based algorithms to deep learning-based algorithms, which has made a qualitative leap in both detection accuracy and detection speed. With the advancement of deep learning, object detection techniques are increasingly becoming a part of everyday life, with the YOLO series of algorithms being extensively applied in various industries. In this paper, we initially present the frequently utilized datasets and evaluation criteria for object detection. Subsequently, we delve into the evolution of traditional object detection algorithms, highlighting two-stage and one-stage approaches through illustrative examples of classical methods. We also conduct a comprehensive summary and analysis of the detection results obtained by these methods. In addition, we introduce object detection applications in daily life, as well as the importance and some difficulties of these applications. Finally, we analyze and summarize the difficulties and challenges facing the task of object detection, and we look forward to the future development direction of object detection.}
}


@article{survey_small_detection,
title = {Recent advances in small object detection based on deep learning: A review},
journal = {Image and Vision Computing},
volume = {97},
pages = {103910},
year = {2020},
issn = {0262-8856},
doi = {https://doi.org/10.1016/j.imavis.2020.103910},
author = {Kang Tong and Yiquan Wu and Fei Zhou},
keywords = {Small object detection, Deep learning, Computer vision, Convolutional neural networks},
abstract = {Small object detection is a challenging problem in computer vision. It has been widely applied in defense military, transportation, industry, etc. To facilitate in-depth understanding of small object detection, we comprehensively review the existing small object detection methods based on deep learning from five aspects, including multi-scale feature learning, data augmentation, training strategy, context-based detection and GAN-based detection. Then, we thoroughly analyze the performance of some typical small object detection algorithms on popular datasets, such as MS-COCO, PASCAL-VOC. Finally, the possible research directions in the future are pointed out from five perspectives: emerging small object detection datasets and benchmarks, multi-task joint learning and optimization, information transmission, weakly supervised small object detection methods and framework for small object detection task.}
}

% --------------Introduction
@misc{sdgs,
author = {United Nations, Department of Economic and Social Affairs - Sustainable Development},
title = {Transforming our world: the 2030 Agenda for Sustainable Development},
pages = {16301},
ISBN = {A/RES/70/1},
URL = {https://sdgs.un.org/2030agenda},
year = {2015},
type = {General Assembly}
}

@article{waste_iniative,
title = {The role of global waste management and circular economy towards carbon neutrality},
journal = {Sustainable Production and Consumption},
volume = {52},
pages = {498-510},
year = {2024},
issn = {2352-5509},
doi = {https://doi.org/10.1016/j.spc.2024.11.021},
author = {Phyo Zaw Oo and Trakarn Prapaspongsa and Vladimir Strezov and Nazmul Huda and Kazuyuki Oshita and Masaki Takaoka and Jun Ren and Anthony Halog and Shabbir H. Gheewala},
keywords = {Solid waste management, Circular economy, Life cycle assessment, Greenhouse gas emissions, Carbon neutrality, Global waste targets},
}

@misc{eurostat2024,
  author = {{Eurostat}},
  title = {Municipal waste down by 19 kg per person in 2022},
  year = {2024},
  url = {https://ec.europa.eu/eurostat/en/web/products-eurostat-news/w/ddn-20240208-2},
  note = {Accessed: 2024-11-11}
}

@misc{nso2023,
  author = {{NSO Malta}},
  title = {Municipal Waste: 2022},
  year = {2023},
  url = {https://nso.gov.mt/municipal-waste-2022-2/},
  note = {Accessed: 2024-11-11}
}

@inproceedings{cortesi2023mini,
  title={Mini UAV-based litter detection on river banks},
  author={Cortesi, I and Mugnai, F and Angelini, R and Masiero, A and others},
  booktitle={ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences, Volume X-4/W1-2022 GeoSpatial Conference 2022--Joint 6th SMPR and 4th GIResearch Conferences, 19--22 February 2023, Tehran, Iran (virtual)},
  volume={10},
  pages={117--122},
  year={2023},
  organization={ISPRS}
}


@article{deep_learning_review,
author = {LeCun, Yann and Bengio, Y. and Hinton, Geoffrey},
year = {2015},
month = {05},
pages = {436-44},
title = {Deep Learning},
volume = {521},
journal = {Nature},
doi = {10.1038/nature14539}
}

@article{ann_guide,
author = {Grossi, Enzo and Buscema, Massimo},
year = {2008},
month = {01},
pages = {1046-54},
title = {Introduction to artificial neural networks},
volume = {19},
journal = {European journal of gastroenterology \& hepatology},
doi = {10.1097/MEG.0b013e3282f198a0}
}

@article{mcculloch_pits_neuron,
  added-at = {2008-02-26T11:58:58.000+0100},
  author = {Mcculloch, Warren and Pitts, Walter},
  citeulike-article-id = {2380493},
  description = {idsia},
  interhash = {3e8e0d06f376f3eb95af89d5a2f15957},
  intrahash = {6fbacb0ae04bc17d296d9265dfc90dff},
  journal = {Bulletin of Mathematical Biophysics},
  keywords = {evolutionary},
  pages = {127--147},
  priority = {2},
  timestamp = {2008-02-26T12:00:58.000+0100},
  title = {A Logical Calculus of Ideas Immanent in Nervous Activity},
  volume = {5},
  year = {1943}
}

@article{cnns,
author = {Bengio, Y. and Lecun, Yann},
year = {1997},
month = {11},
pages = {},
title = {Convolutional Networks for Images, Speech, and Time-Series}
}

@INPROCEEDINGS{image_net,
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Kai Li and Li Fei-Fei},
  booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={ImageNet: A large-scale hierarchical image database}, 
  year={2009},
  volume={},
  number={},
  pages={248-255},
  keywords={Large-scale systems;Image databases;Explosions;Internet;Robustness;Information retrieval;Image retrieval;Multimedia databases;Ontologies;Spine},
  doi={10.1109/CVPR.2009.5206848}}

@unknown{overview_cv,
author = {Moin, Tanvir},
year = {2023},
month = {06},
pages = {},
title = {Overview of Computer Vision},
doi = {10.13140/RG.2.2.13989.68327}
}

@article{od_survey_problems,
title = {Development and challenges of object detection: A survey},
journal = {Neurocomputing},
volume = {598},
pages = {128102},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.128102},
author = {Zonghui Li and Yongsheng Dong and Longchao Shen and Yafeng Liu and Yuanhua Pei and Haotian Yang and Lintao Zheng and Jinwen Ma},
keywords = {Object detection, Deep learning, Datasets, Evaluation metrics, Difficulties and challenges},
abstract = {Object detection is a basic vision task that accompanies people’s daily lives all the time. The development of object detection technology has experienced an evolution from traditional-based algorithms to deep learning-based algorithms, which has made a qualitative leap in both detection accuracy and detection speed. With the advancement of deep learning, object detection techniques are increasingly becoming a part of everyday life, with the YOLO series of algorithms being extensively applied in various industries. In this paper, we initially present the frequently utilized datasets and evaluation criteria for object detection. Subsequently, we delve into the evolution of traditional object detection algorithms, highlighting two-stage and one-stage approaches through illustrative examples of classical methods. We also conduct a comprehensive summary and analysis of the detection results obtained by these methods. In addition, we introduce object detection applications in daily life, as well as the importance and some difficulties of these applications. Finally, we analyze and summarize the difficulties and challenges facing the task of object detection, and we look forward to the future development direction of object detection.}
}

@ARTICLE{four_pillars_od,
  author={Chen, Guang and Wang, Haitao and Chen, Kai and Li, Zhijun and Song, Zida and Liu, Yinlong and Chen, Wenkai and Knoll, Alois},
  journal={IEEE Transactions on Systems, Man, and Cybernetics: Systems}, 
  title={A Survey of the Four Pillars for Small Object Detection: Multiscale Representation, Contextual Information, Super-Resolution, and Region Proposal}, 
  year={2022},
  volume={52},
  number={2},
  pages={936-953},
  keywords={Object detection;Feature extraction;Detectors;Image resolution;Machine learning;Roads;Task analysis;Contextual information;multiscale representation;region proposal;small object dataset;small object detection;super-resolution},
  doi={10.1109/TSMC.2020.3005231}}

@article{survey_od_2,
  title={Object detection in 20 years: A survey},
  author={Zou, Zhengxia and Chen, Keyan and Shi, Zhenwei and Guo, Yuhong and Ye, Jieping},
  journal={Proceedings of the IEEE},
  volume={111},
  number={3},
  pages={257--276},
  year={2023},
  publisher={IEEE}
}

@article{od_problem,
author = {Prasad, Dilip},
year = {2012},
month = {12},
pages = {441},
title = {Survey of The Problem of Object Detection In Real Images},
volume = {6},
journal = {International Journal of Image Processing (IJIP)}
}

@ARTICLE{od_2,
  author={Zhao, Zhong-Qiu and Zheng, Peng and Xu, Shou-Tao and Wu, Xindong},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Object Detection With Deep Learning: A Review}, 
  year={2019},
  volume={30},
  number={11},
  pages={3212-3232},
  keywords={Object detection;Deep learning;Task analysis;Feature extraction;Computer architecture;Training;Neural networks;Deep learning;neural network;object detection},
  doi={10.1109/TNNLS.2018.2876865}}

@article{small_detection_survey,
title = {A survey and performance evaluation of deep learning methods for small object detection},
journal = {Expert Systems with Applications},
volume = {172},
pages = {114602},
year = {2021},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.114602},
author = {Yang Liu and Peng Sun and Nickolas Wergeles and Yi Shang},
keywords = {Small object detection, Computer vision, Convolutional neural networks, Deep learning},
abstract = {In computer vision, significant advances have been made on object detection with the rapid development of deep convolutional neural networks (CNN). This paper provides a comprehensive review of recently developed deep learning methods for small object detection. We summarize challenges and solutions of small object detection, and present major deep learning techniques, including fusing feature maps, adding context information, balancing foreground-background examples, and creating sufficient positive examples. We discuss related techniques developed in four research areas, including generic object detection, face detection, object detection in aerial imagery, and segmentation. In addition, this paper compares the performances of several leading deep learning methods for small object detection, including YOLOv3, Faster R-CNN, and SSD, based on three large benchmark datasets of small objects. Our experimental results show that while the detection accuracy on small objects by these deep learning methods was low, less than 0.4, Faster R-CNN performed the best, while YOLOv3 was a close second.}
}

@article{imbalance,
  author       = {Kemal Oksuz and
                  Baris Can Cam and
                  Sinan Kalkan and
                  Emre Akbas},
  title        = {Imbalance Problems in Object Detection: {A} Review},
  journal      = {CoRR},
  volume       = {abs/1909.00169},
  year         = {2019},
  eprinttype    = {arXiv},
  eprint       = {1909.00169},
  timestamp    = {Mon, 16 Sep 2019 17:27:14 +0200},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

% Background for traditional methods
@article{garcia2020background,
  title={Background subtraction in real applications: Challenges, current models and future directions},
  author={Garcia-Garcia Belmar and Bouwmans, Thierry and Silva, Alberto Jorge Rosales},
  journal={Computer Science Review},
  volume={35},
  pages={100204},
  year={2020},
  publisher={Elsevier}
}

@inproceedings{vinh2020real,
  title={Real-time face mask detector using {YOLOv3} algorithm and Haar cascade classifier},
  author={Vinh, Truong Quang and Anh, Nguyen Tran Ngoc},
  booktitle={2020 international conference on advanced computing and applications (ACOMP)},
  pages={146--149},
  year={2020},
  organization={IEEE}
}

@inproceedings{javed2022human,
  title={Human face recognition applying haar cascade classifier},
  author={Javed Mehedi Shamrat, FM and Majumder, Anup and Antu, Probal Roy and Barmon, Saykot Kumar and Nowrin, Itisha and Ranjan, Rumesh},
  booktitle={Pervasive Computing and Social Networking: Proceedings of ICPCSN 2021},
  pages={143--157},
  year={2022},
  organization={Springer}
}


@inproceedings{dalal2005histograms,
  title={Histograms of oriented gradients for human detection},
  author={Dalal, Navneet and Triggs, Bill},
  booktitle={2005 IEEE computer society conference on computer vision and pattern recognition (CVPR'05)},
  volume={1},
  pages={886--893},
  year={2005},
  organization={Ieee}
}

@article{bhattarai2023histogram,
  title={Histogram of oriented gradients meet deep learning: A novel multi-task deep network for 2D surgical image semantic segmentation},
  author={Bhattarai, Binod and Subedi, Ronast and Gaire, Rebati Raman and Vazquez, Eduard and Stoyanov, Danail},
  journal={Medical Image Analysis},
  volume={85},
  pages={102747},
  year={2023},
  publisher={Elsevier}
}

@article{hearst1998support,
  title={Support vector machines},
  author={Hearst, Marti A. and Dumais, Susan T and Osuna, Edgar and Platt, John and Scholkopf, Bernhard},
  journal={IEEE Intelligent Systems and their applications},
  volume={13},
  number={4},
  pages={18--28},
  year={1998},
  publisher={IEEE}
}

@article{bhatt2023state,
  title={State-of-the-art machine learning techniques for melanoma skin cancer detection and classification: a comprehensive review},
  author={Bhatt, Harsh and Shah, Vrunda and Shah, Krish and Shah, Ruju and Shah, Manan},
  journal={Intelligent Medicine},
  volume={3},
  number={3},
  pages={180--190},
  year={2023},
  publisher={Chinese Medical Association Publishing House Co., Ltd 69 Dongheyan Street~…}
}

@inproceedings{viola2001rapid,
  title={Rapid object detection using a boosted cascade of simple features},
  author={Viola, Paul and Jones, Michael},
  booktitle={Proceedings of the 2001 IEEE computer society conference on computer vision and pattern recognition. CVPR 2001},
  volume={1},
  pages={I-511},
  year={2001},
  organization={IEEE}
}

@inproceedings{saffari2009line,
  title={On-line random forests},
  author={Saffari, Amir and Leistner, Christian and Santner, Jakob and Godec, Martin and Bischof, Horst},
  booktitle={2009 ieee 12th international conference on computer vision workshops, iccv workshops},
  pages={1393--1400},
  year={2009},
  organization={IEEE}
}

@article{felzenszwalb2009object,
  title={Object detection with discriminatively trained part-based models},
  author={Felzenszwalb, Pedro F and Girshick, Ross B and McAllester, David and Ramanan, Deva},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={32},
  number={9},
  pages={1627--1645},
  year={2009},
  publisher={IEEE}
}

@Article{lowe2004distinctive,
  title =        "Distinctive image features from scale-invariant keypoints",
  author =       "David G Lowe",
  journal =      "International journal of computer vision",
  volume =       "60",
  number =       "2",
  pages =        "91--110",
  year =         "2004",
  publisher =    "Springer",
  topic =        "IFET",
}

@Article{bay2006surf,
  author    = {Bay, Herbert and Tuytelaars, Tinne and Van Gool, Luc},
  title     = {S{U}{R}{F}: Speeded {U}p {R}obust {F}eatures},
  journal   = {Proceedings IEEE European Conference on Computer Vision},
  year      = {2006},
  pages     = {404--417},
  publisher = {Springer},
}

@INPROCEEDINGS{rublee2011orb,
  author={Rublee, Ethan and Rabaud, Vincent and Konolige, Kurt and Bradski, Gary},
  booktitle={2011 International Conference on Computer Vision}, 
  title={ORB: An efficient alternative to SIFT or SURF}, 
  year={2011},
  volume={},
  number={},
  pages={2564-2571},
  keywords={Boats},
  doi={10.1109/ICCV.2011.6126544}}

@INPROCEEDINGS{seychell16,
  author={Seychell, Dylan and Debono, Carl James},
  booktitle={2016 Visual Communications and Image Processing (VCIP)}, 
  title={Efficient object selection using depth and texture information}, 
  year={2016},
  volume={},
  number={},
  pages={1-4},
  keywords={Noise reduction;Image color analysis;Object recognition;Image segmentation;Training;Optical sensors;image editing;object selection;scene understanding;texture and depth processing},
  doi={10.1109/VCIP.2016.7805519}}

@INPROCEEDINGS{machine_learning,
  author={Shivahare, Basu Dev and Suman, Shashikant and Challapalli, Sai Sri Nandan and Kaushik, Prakarsh and Gupta, Amar Deep and Bibhu, Vimal},
  booktitle={2022 2nd International Conference on Innovative Practices in Technology and Management (ICIPTM)}, 
  title={Survey Paper: Comparative Study of Machine Learning Techniques and its Recent Applications}, 
  year={2022},
  volume={2},
  number={},
  pages={449-454},
  keywords={Technological innovation;Machine learning algorithms;Linear regression;Machine learning;Lead;Automobiles;Task analysis;Applications of Machine Learning Algorithms;KNN;Linear Regression;Deep Learning;SVM;RF;Activation functions},
  doi={10.1109/ICIPTM54933.2022.9754206}}

% Background for dl methods
@article{one_two_stage_detection,
  author       = {Xin Lu and
                  Quanquan Li and
                  Buyu Li and
                  Junjie Yan},
  title        = {MimicDet: Bridging the Gap Between One-Stage and Two-Stage Object
                  Detection},
  journal      = {CoRR},
  volume       = {abs/2009.11528},
  year         = {2020},
  eprinttype    = {arXiv},
  eprint       = {2009.11528},
  timestamp    = {Wed, 30 Sep 2020 16:16:22 +0200},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{cnn_survey,
  author={Li, Zewen and Liu, Fan and Yang, Wenjie and Peng, Shouheng and Zhou, Jun},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={A Survey of Convolutional Neural Networks: Analysis, Applications, and Prospects}, 
  year={2022},
  volume={33},
  number={12},
  pages={6999-7019},
  keywords={Convolutional neural networks;Feature extraction;Neurons;Deep learning;Computer vision;Computer vision;convolutional neural networks (CNNs);deep learning;deep neural networks},
  doi={10.1109/TNNLS.2021.3084827}

}

@inproceedings{alexnet,
  author       = {Alex Krizhevsky and
                  Ilya Sutskever and
                  Geoffrey E. Hinton},
  editor       = {Peter L. Bartlett and
                  Fernando C. N. Pereira and
                  Christopher J. C. Burges and
                  L{\'{e}}on Bottou and
                  Kilian Q. Weinberger},
  title        = {ImageNet Classification with Deep Convolutional Neural Networks},
  booktitle    = {Advances in Neural Information Processing Systems 25: 26th Annual
                  Conference on Neural Information Processing Systems 2012. Proceedings
                  of a meeting held December 3-6, 2012, Lake Tahoe, Nevada, United States},
  pages        = {1106--1114},
  year         = {2012},
  timestamp    = {Mon, 16 May 2022 15:41:51 +0200},
}

@ARTICLE{multitask_learning,
  author={Wang, Yan and Zhang, Lei and Wang, Lituan and Wang, Zizhou},
  journal={IEEE Transactions on Cognitive and Developmental Systems}, 
  title={Multitask Learning for Object Localization With Deep Reinforcement Learning}, 
  year={2019},
  volume={11},
  number={4},
  pages={573-580},
  keywords={Reinforcement learning;Search problems;Feature extraction;Training;Deep Q-network (DQN);multitask learning;object localization;reinforcement learning (RL)},
  doi={10.1109/TCDS.2018.2885813}}

@article{reinforcenet,
  title={ReinforceNet: A reinforcement learning embedded object detection framework with region selection network},
  author={Man Zhou and Rujing Wang and Chengjun Xie and Liu Liu and Rui Li and Fangyuan Wang and Dengshan Li},
  journal={Neurocomputing},
  year={2021},
  volume={443},
  pages={369-379},
}

@article{bar_rl, title={BAR — A Reinforcement Learning Agent for Bounding-Box Automated Refinement}, volume={34}, number={03}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Ayle, Morgane and Tekli, Jimmy and El-Zini, Julia and El-Asmar, Boulos and Awad, Mariette}, year={2020}, month={4}, pages={2561-2568} }

@article{detr,
  author       = {Nicolas Carion and
                  Francisco Massa and
                  Gabriel Synnaeve and
                  Nicolas Usunier and
                  Alexander Kirillov and
                  Sergey Zagoruyko},
  title        = {End-to-End Object Detection with Transformers},
  journal      = {CoRR},
  volume       = {abs/2005.12872},
  year         = {2020},
  eprinttype    = {arXiv},
  eprint       = {2005.12872},
  timestamp    = {Thu, 28 May 2020 17:38:09 +0200},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{fasterrcnn,
  author       = {Shaoqing Ren and
                  Kaiming He and
                  Ross B. Girshick and
                  Jian Sun},
  title        = {Faster {R-CNN:} Towards Real-Time Object Detection with Region Proposal
                  Networks},
  journal      = {CoRR},
  volume       = {abs/1506.01497},
  year         = {2015},
  eprinttype    = {arXiv},
  eprint       = {1506.01497},
  timestamp    = {Mon, 13 Aug 2018 16:46:02 +0200},
}

@article{rfcn,
  author       = {Jifeng Dai and
                  Yi Li and
                  Kaiming He and
                  Jian Sun},
  title        = {{R-FCN:} Object Detection via Region-based Fully Convolutional Networks},
  journal      = {CoRR},
  volume       = {abs/1605.06409},
  year         = {2016},
  eprinttype    = {arXiv},
  eprint       = {1605.06409},
  timestamp    = {Tue, 15 Sep 2020 14:17:39 +0200},
}

@article{transformers,
  author       = {Ashish Vaswani and
                  Noam Shazeer and
                  Niki Parmar and
                  Jakob Uszkoreit and
                  Llion Jones and
                  Aidan N. Gomez and
                  Lukasz Kaiser and
                  Illia Polosukhin},
  title        = {Attention Is All You Need},
  journal      = {CoRR},
  volume       = {abs/1706.03762},
  year         = {2017},
  eprinttype    = {arXiv},
  eprint       = {1706.03762},
  timestamp    = {Sat, 23 Jan 2021 01:20:40 +0100},
}

@inproceedings{feature_learning,
	title        = {Feature Extraction using Convolution Neural Networks (CNN) and Deep Learning},
	author       = {Jogin, Manjunath and ., Mohana and Madhulika, M and Divya, G and Meghana, R and Apoorva, S},
	year         = 2018,
	month        = {05},
	pages        = {2319--2323},
	doi          = {10.1109/RTEICT42901.2018.9012507}
}

@misc{yolo,
  abstract = {We present YOLO, a new approach to object detection. Prior work on object
detection repurposes classifiers to perform detection. Instead, we frame object
detection as a regression problem to spatially separated bounding boxes and
associated class probabilities. A single neural network predicts bounding boxes
and class probabilities directly from full images in one evaluation. Since the
whole detection pipeline is a single network, it can be optimized end-to-end
directly on detection performance.
  Our unified architecture is extremely fast. Our base YOLO model processes
images in real-time at 45 frames per second. A smaller version of the network,
Fast YOLO, processes an astounding 155 frames per second while still achieving
double the mAP of other real-time detectors. Compared to state-of-the-art
detection systems, YOLO makes more localization errors but is far less likely
to predict false detections where nothing exists. Finally, YOLO learns very
general representations of objects. It outperforms all other detection methods,
including DPM and R-CNN, by a wide margin when generalizing from natural images
to artwork on both the Picasso Dataset and the People-Art Dataset.},
  added-at = {2018-07-03T09:21:25.000+0200},
  author = {Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
  description = {[1506.02640] You Only Look Once: Unified, Real-Time Object Detection},
  interhash = {0ef664b242961e356a0e08d2c05ba337},
  intrahash = {d97e27b4931789f2c26da2f1e1a4f873},
  keywords = {2016 arxiv computer-vision cvpr detection paper},
  note = {cite arxiv:1506.02640},
  timestamp = {2021-11-25T14:11:37.000+0100},
  title = {You Only Look Once: Unified, Real-Time Object Detection},
  year = {2016}
}

@INPROCEEDINGS{yolov2,
  author={Redmon, Joseph and Farhadi, Ali},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={YOLO9000: Better, Faster, Stronger}, 
  year={2017},
  volume={},
  number={},
  pages={6517-6525},
  keywords={Image resolution;Feature extraction;Training;Real-time systems;Object detection;Detectors},
  doi={10.1109/CVPR.2017.690}}

@misc{overfeat,
  abstract = {We present an integrated framework for using Convolutional Networks for
classification, localization and detection. We show how a multiscale and
sliding window approach can be efficiently implemented within a ConvNet. We
also introduce a novel deep learning approach to localization by learning to
predict object boundaries. Bounding boxes are then accumulated rather than
suppressed in order to increase detection confidence. We show that different
tasks can be learned simultaneously using a single shared network. This
integrated framework is the winner of the localization task of the ImageNet
Large Scale Visual Recognition Challenge 2013 (ILSVRC2013) and obtained very
competitive results for the detection and classifications tasks. In
post-competition work, we establish a new state of the art for the detection
task. Finally, we release a feature extractor from our best model called
OverFeat.},
  added-at = {2019-07-11T10:32:19.000+0200},
  author = {Sermanet, Pierre and Eigen, David and Zhang, Xiang and Mathieu, Michael and Fergus, Rob and LeCun, Yann},
  description = {OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks},
  interhash = {6ded0a252b40f5c6cb4b997fb8ca074d},
  intrahash = {9d9b7e83a918116a22055acd6e05d2b6},
  keywords = {machinelearn},
  note = {cite arxiv:1312.6229},
  timestamp = {2019-07-11T10:32:19.000+0200},
  title = {OverFeat: Integrated Recognition, Localization and Detection using
  Convolutional Networks},
  year = {2013}
}

@article{fastrcnn,
  abstract = {This paper proposes a Fast Region-based Convolutional Network method (Fast R-CNN) for object detection. Fast R-CNN builds on previous work to efficiently classify object proposals using deep convolutional networks. Compared
to previous work, Fast R-CNN employs several innovations to improve training and testing speed while also increasing detection accuracy. Fast R-CNN trains the very
deep VGG16 network 9× faster than R-CNN, is 213× faster at test-time, and achieves a higher mAP on PASCAL VOC 2012. Compared to SPPnet, Fast R-CNN trains VGG16 3× faster, tests 10× faster, and is more accurate. Fast R-CNN
is implemented in Python and C++ (using Caffe) and is available under the open-source MIT License at https: //github.com/rbgirshick/fast-rcnn.},
  added-at = {2017-04-19T21:06:53.000+0200},
  author = {Girshick, Ross},
  interhash = {51c671e48116130c4810b16bc8403b69},
  intrahash = {9e600f207cdf002feee65c43d18a98dd},
  journal = {CoRR},
  keywords = {cnn detection fast image object R-CNN thema thema:RCNN},
  timestamp = {2017-04-25T13:24:08.000+0200},
  title = {Fast R-CNN},
  volume = {abs/1504.08083},
  year = {2015},
}

@incollection{ssd,
  author       = {Wei Liu and
                  Dragomir Anguelov and
                  Dumitru Erhan and
                  Christian Szegedy and
                  Scott E. Reed and
                  Cheng{-}Yang Fu and
                  Alexander C. Berg},
  editor       = {Bastian Leibe and
                  Jiri Matas and
                  Nicu Sebe and
                  Max Welling},
  title        = {{SSD:} Single Shot MultiBox Detector},
  booktitle    = {Computer Vision - {ECCV} 2016 - 14th European Conference, Amsterdam,
                  The Netherlands, October 11-14, 2016, Proceedings, Part {I}},
  series       = {Lecture Notes in Computer Science},
  volume       = {9905},
  pages        = {21--37},
  publisher    = {Springer},
  year         = {2016},
  doi          = {10.1007/978-3-319-46448-0\_2},
}


@inproceedings{dcn,
  author       = {Jifeng Dai and Haozhi Qi and Yuwen Xiong and Yi Li and Guodong Zhang and Han Hu and Yichen Wei},
  title        = {Deformable Convolutional Networks},
  booktitle    = {2017 {IEEE} International Conference on Computer Vision ({ICCV})},
  address      = {Venice, Italy},
  date         = {2017-10-22/2017-10-29},
  pages        = {764--773},
  publisher    = {{IEEE} Computer Society},
  year         = {2017},
  doi          = {10.1109/ICCV.2017.89},
  isbn         = {978-1-5386-1032-9},
  timestamp    = {2023-09-30T09:44:37+0200}
}


@inproceedings{retinanet,
  author       = {Tsung{-}Yi Lin and Priya Goyal and Ross B. Girshick and Kaiming He and Piotr Doll{\'{a}}r},
  title        = {Focal Loss for Dense Object Detection},
  booktitle    = {2017 {IEEE} International Conference on Computer Vision ({ICCV})},
  address      = {Venice, Italy},
  date         = {2017-10-22/2017-10-29},
  pages        = {2999--3007},
  publisher    = {{IEEE} Computer Society},
  isbn         = {978-1-5386-1032-9},
  doi          = {10.1109/ICCV.2017.324},
  timestamp    = {2023-03-23T23:57:41+0100},
  year={2017}
}


@article{resnet,
  author       = {Kaiming He and
                  Xiangyu Zhang and
                  Shaoqing Ren and
                  Jian Sun},
  title        = {Deep Residual Learning for Image Recognition},
  journal      = {CoRR},
  volume       = {abs/1512.03385},
  year         = {2015},
  eprinttype    = {arXiv},
  eprint       = {1512.03385},
  timestamp    = {Wed, 25 Jan 2023 11:01:16 +0100},
}

@article{yolov3,
  author       = {Joseph Redmon and
                  Ali Farhadi},
  title        = {YOLOv3: An Incremental Improvement},
  journal      = {CoRR},
  volume       = {abs/1804.02767},
  year         = {2018},
  eprinttype    = {arXiv},
  eprint       = {1804.02767},
  timestamp    = {Mon, 13 Aug 2018 16:48:24 +0200},
}

@article{efficientdet,
  author       = {Mingxing Tan and
                  Ruoming Pang and
                  Quoc V. Le},
  title        = {EfficientDet: Scalable and Efficient Object Detection},
  journal      = {CoRR},
  volume       = {abs/1911.09070},
  year         = {2019},
  eprinttype    = {arXiv},
  eprint       = {1911.09070},
  timestamp    = {Tue, 03 Dec 2019 14:15:54 +0100},
}

@inproceedings{efficientnet,
  author       = {Mingxing Tan and Quoc V. Le},
  editor       = {Kamalika Chaudhuri and Ruslan Salakhutdinov},
  title        = {EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks},
  booktitle    = {Proceedings of the 36th International Conference on Machine Learning ({ICML})},
  address      = {Long Beach, California, USA},
  date         = {2019-06-09/2019-06-15},
  series       = {Proceedings of Machine Learning Research},
  volume       = {97},
  pages        = {6105--6114},
  publisher    = {{PMLR}},
  year         = {2019},
  doi          = {10.5555/3305890.3306031},
  timestamp    = {2019-06-11T15:37:38+0200}
}

@inproceedings{fcos,
  author       = {Zhi Tian and Chunhua Shen and Hao Chen and Tong He},
  title        = {{FCOS: Fully Convolutional One-Stage Object Detection}},
  booktitle    = {2019 {IEEE/CVF} International Conference on Computer Vision ({ICCV})},
  address      = {Seoul, Korea (South)},
  date         = {2019-10-27/2019-11-02},
  pages        = {9626--9635},
  publisher    = {{IEEE}},
  year         = {2019},
  doi          = {10.1109/ICCV.2019.00972},
  timestamp    = {2023-03-07T08:43:12+0100}
}


@article{centernet,
  author       = {Xingyi Zhou and
                  Dequan Wang and
                  Philipp Kr{\"{a}}henb{\"{u}}hl},
  title        = {Objects as Points},
  journal      = {CoRR},

  year         = {2019},
  eprinttype    = {arXiv},
  eprint       = {1904.07850},
  timestamp    = {Fri, 26 Apr 2019 13:18:53 +0200},
}

@article{fpn,
  author       = {Tsung{-}Yi Lin and
                  Piotr Doll{\'{a}}r and
                  Ross B. Girshick and
                  Kaiming He and
                  Bharath Hariharan and
                  Serge J. Belongie},
  title        = {Feature Pyramid Networks for Object Detection},
  journal      = {CoRR},
  volume       = {abs/1612.03144},
  year         = {2016},
  eprinttype    = {arXiv},
  eprint       = {1612.03144},
  timestamp    = {Mon, 13 Aug 2018 16:48:50 +0200},
}

@inproceedings{maskrcnn,
  author       = {Kaiming He and Georgia Gkioxari and Piotr Doll{\'a}r and Ross B. Girshick},
  title        = {Mask {R-CNN}},
  booktitle    = {2017 {IEEE} International Conference on Computer Vision ({ICCV})},
  address      = {Venice, Italy},
  date         = {2017-10-22/2017-10-29},
  pages        = {2980--2988},
  publisher    = {{IEEE} Computer Society},
  isbn         = {978-1-5386-1032-9},
  doi          = {10.1109/ICCV.2017.322},
  timestamp    = {2023-12-12T21:55:40.000+0100}
}


@article{rcnn,
  author       = {Ross B. Girshick and
                  Jeff Donahue and
                  Trevor Darrell and
                  Jitendra Malik},
  title        = {Rich feature hierarchies for accurate object detection and semantic
                  segmentation},
  journal      = {CoRR},
  volume       = {abs/1311.2524},
  year         = {2013},
  eprinttype    = {arXiv},
  eprint       = {1311.2524},
  timestamp    = {Mon, 13 Aug 2018 16:48:09 +0200},
}

@misc{yolov9,
      title={YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information}, 
      author={Chien-Yao Wang and I-Hau Yeh and Hong-Yuan Mark Liao},
      year={2024},
      eprint={2402.13616},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{yolov10,
      title={YOLOv10: Real-Time End-to-End Object Detection}, 
      author={Ao Wang and Hui Chen and Lihao Liu and Kai Chen and Zijia Lin and Jungong Han and Guiguang Ding},
      year={2024},
      eprint={2405.14458},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
}

@misc{bartolo2024integratingsaliencyrankingreinforcement,
      title={Integrating Saliency Ranking and Reinforcement Learning for Enhanced Object Detection}, 
      author={Matthias Bartolo and Dylan Seychell and Josef Bajada},
      year={2024},
      eprint={2408.06803},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
}

@misc{bartolo2024correlationobjectdetectionperformance,
      title={Correlation of Object Detection Performance with Visual Saliency and Depth Estimation}, 
      author={Matthias Bartolo and Dylan Seychell},
      year={2024},
      eprint={2411.02844},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
}

@InProceedings{Caicedo_2015_ICCV,
author = {Caicedo, Juan C. and Lazebnik, Svetlana},
title = {Active Object Localization With Deep Reinforcement Learning},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
month = {12},
year = {2015}
}
@article{duangsuwan2024drone,
  title={Drone-Enabled AI Edge Computing and 5G Communication Network for Real-Time Coastal Litter Detection},
  author={Duangsuwan, Sarun and Prapruetdee, Phoowadon},
  journal={Drones},
  volume={8},
  number={12},
  pages={750},
  year={2024},
  publisher={MDPI}
}
@article{moore1998cramming,
  title={Cramming more components onto integrated circuits},
  author={Moore, Gordon E},
  journal={Proceedings of the IEEE},
  volume={86},
  number={1},
  pages={82--85},
  year={1998},
  publisher={Ieee}
}

@article{visiontransformer,
	title        = {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
	author       = {Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
	year         = 2020,
	journal      = {CoRR},
	volume       = {abs/2010.11929},
	eprinttype   = {arXiv},
	eprint       = {2010.11929},
	timestamp    = {Fri, 20 Nov 2020 14:04:05 +0100},
}

@misc{florence2,
      title={Florence-2: Advancing a Unified Representation for a Variety of Vision Tasks}, 
      author={Bin Xiao and Haiping Wu and Weijian Xu and Xiyang Dai and Houdong Hu and Yumao Lu and Michael Zeng and Ce Liu and Lu Yuan},
      year={2023},
      eprint={2311.06242},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
}

@article{yolox,
  author       = {Zheng Ge and
                  Songtao Liu and
                  Feng Wang and
                  Zeming Li and
                  Jian Sun},
  title        = {{YOLOX:} Exceeding {YOLO} Series in 2021},
  journal      = {CoRR},
  volume       = {abs/2107.08430},
  year         = {2021},
  eprinttype    = {arXiv},
  eprint       = {2107.08430},
  timestamp    = {Tue, 05 Apr 2022 14:09:44 +0200},
}

@misc{yolonas,
      doi = {10.5281/ZENODO.7789328},
      author = {Aharon,  Shay and {Louis-Dupont} and {Ofri Masad} and Yurkova,  Kate and {Lotem Fridman} and {Lkdci} and Khvedchenya,  Eugene and Rubin,  Ran and Bagrov,  Natan and Tymchenko,  Borys and Keren,  Tomer and Zhilko,  Alexander and {Eran-Deci}},
      title = {Super-Gradients},
      publisher = {GitHub},
      journal = {GitHub repository},
      year = {2021},
}

@article{yolov4,
  author       = {Alexey Bochkovskiy and
                  Chien{-}Yao Wang and
                  Hong{-}Yuan Mark Liao},
  title        = {YOLOv4: Optimal Speed and Accuracy of Object Detection},
  journal      = {CoRR},
  volume       = {abs/2004.10934},
  year         = {2020},
  eprinttype    = {arXiv},
  eprint       = {2004.10934},
  timestamp    = {Tue, 28 Apr 2020 16:10:02 +0200},
}

@software{yolov5,
author = {Glenn Jocher},
title = {{ultralytics/yolov5: v3.1 - Bug Fixes and
Performance Improvements}},
month = {10},
year = {2020},
publisher = {Zenodo},
version = {v3.1},
doi = {10.5281/zenodo.4154370},
url = {https://doi.org/10.5281/zenodo.4154370},
howpublished = {\url{https://github.com/ultralytics/yolov5}}
}

@article{bagoffreebies,
  author       = {Zhi Zhang and
                  Tong He and
                  Hang Zhang and
                  Zhongyue Zhang and
                  Junyuan Xie and
                  Mu Li},
  title        = {Bag of Freebies for Training Object Detection Neural Networks},
  journal      = {CoRR},
  volume       = {abs/1902.04103},
  year         = {2019},
  eprinttype    = {arXiv},
  eprint       = {1902.04103},
  timestamp    = {Tue, 21 Mar 2023 20:02:49 +0100},
}

@article{cspdarknet,
  author       = {Chien{-}Yao Wang and
                  Hong{-}Yuan Mark Liao and
                  I{-}Hau Yeh and
                  Yueh{-}Hua Wu and
                  Ping{-}Yang Chen and
                  Jun{-}Wei Hsieh},
  title        = {CSPNet: {A} New Backbone that can Enhance Learning Capability of {CNN}},
  journal      = {CoRR},
  volume       = {abs/1911.11929},
  year         = {2019},
  eprinttype    = {arXiv},
  eprint       = {1911.11929},
  timestamp    = {Tue, 03 Dec 2019 20:41:07 +0100},
}

@article{yolov6,
  author       = {Chuyi Li and
                  Lulu Li and
                  Hongliang Jiang and
                  Kaiheng Weng and
                  Yifei Geng and
                  Liang Li and
                  Zaidan Ke and
                  Qingyuan Li and
                  Meng Cheng and
                  Weiqiang Nie and
                  Yiduo Li and
                  Bo Zhang and
                  Yufei Liang and
                  Linyuan Zhou and
                  Xiaoming Xu and
                  Xiangxiang Chu and
                  Xiaoming Wei and
                  Xiaolin Wei},
  title        = {YOLOv6: {A} Single-Stage Object Detection Framework for Industrial
                  Applications},
  journal      = {CoRR},
  volume       = {abs/2209.02976},
  year         = {2022},
  doi          = {10.48550/ARXIV.2209.02976},
  eprinttype    = {arXiv},
  eprint       = {2209.02976},
  timestamp    = {Tue, 19 Mar 2024 11:28:08 +0100},
}

@misc{yolov7,
      title={YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors}, 
      author={Chien-Yao Wang and Alexey Bochkovskiy and Hong-Yuan Mark Liao},
      year={2022},
      eprint={2207.02696},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
}

@software{yolov8,
  author = {Glenn Jocher and Ayush Chaurasia and Jing Qiu},
  title = {Ultralytics YOLOv8},
  version = {8.0.0},
  year = {2023},
  url = {https://github.com/ultralytics/ultralytics},
  orcid = {0000-0001-5950-6979, 0000-0002-7603-6750, 0000-0003-3783-7069},
  license = {AGPL-3.0}
}

@INPROCEEDINGS{va_detection,
  author={Silva Machado, Eduardo Manuel and Carrillo, Ivan and Collado, Miguel and Chen, Liming},
  booktitle={2019 IEEE SmartWorld, Ubiquitous Intelligence \& Computing, Advanced \& Trusted Computing, Scalable Computing \& Communications, Cloud \& Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)}, 
  title={Visual Attention-Based Object Detection in Cluttered Environments}, 
  year={2019},
  volume={},
  number={},
  pages={133-139},
  keywords={Visualization;Object detection;Feature extraction;Task analysis;Cameras;Object recognition;Psychology;Object Detection;Visual Attention;Cluttered Environments;Fixations;Deep Learning},
  doi={10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00064}}

@misc{groundingdino,
      title={Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection}, 
      author={Shilong Liu and Zhaoyang Zeng and Tianhe Ren and Feng Li and Hao Zhang and Jie Yang and Qing Jiang and Chunyuan Li and Jianwei Yang and Hang Su and Jun Zhu and Lei Zhang},
      year={2024},
      eprint={2303.05499},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
}
@misc{zhang2025uavdetrefficientendtoendobject,
      title={UAV-DETR: Efficient End-to-End Object Detection for Unmanned Aerial Vehicle Imagery}, 
      author={Huaxiang Zhang and Kai Liu and Zhongxue Gan and Guo-Niu Zhu},
      year={2025},
      eprint={2501.01855},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
}
@misc{rt-detrv2,
      title={RT-DETRv2: Improved Baseline with Bag-of-Freebies for Real-Time Detection Transformer}, 
      author={Wenyu Lv and Yian Zhao and Qinyao Chang and Kui Huang and Guanzhong Wang and Yi Liu},
      year={2024},
      eprint={2407.17140},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
}

@article{paligemma,
  author       = {Lucas Beyer and
                  Andreas Steiner and
                  Andr{\'{e}} Susano Pinto and
                  Alexander Kolesnikov and
                  Xiao Wang and
                  Daniel Salz and
                  Maxim Neumann and
                  Ibrahim Alabdulmohsin and
                  Michael Tschannen and
                  Emanuele Bugliarello and
                  Thomas Unterthiner and
                  Daniel Keysers and
                  Skanda Koppula and
                  Fangyu Liu and
                  Adam Grycner and
                  Alexey A. Gritsenko and
                  Neil Houlsby and
                  Manoj Kumar and
                  Keran Rong and
                  Julian Eisenschlos and
                  Rishabh Kabra and
                  Matthias Bauer and
                  Matko Bosnjak and
                  Xi Chen and
                  Matthias Minderer and
                  Paul Voigtlaender and
                  Ioana Bica and
                  Ivana Balazevic and
                  Joan Puigcerver and
                  Pinelopi Papalampidi and
                  Olivier J. H{\'{e}}naff and
                  Xi Xiong and
                  Radu Soricut and
                  Jeremiah Harmsen and
                  Xiaohua Zhai},
  title        = {PaliGemma: {A} versatile 3B {VLM} for transfer},
  journal      = {CoRR},

  year         = {2024},
  doi          = {10.48550/ARXIV.2407.07726},
  eprinttype    = {arXiv},
  eprint       = {2407.07726},
  timestamp    = {Sun, 06 Oct 2024 21:25:24 +0200},
}

@article{paligemma2,
  author       = {Andreas Steiner and
                  Andr{\'{e}} Susano Pinto and
                  Michael Tschannen and
                  Daniel Keysers and
                  Xiao Wang and
                  Yonatan Bitton and
                  Alexey A. Gritsenko and
                  Matthias Minderer and
                  Anthony Sherbondy and
                  Shangbang Long and
                  Siyang Qin and
                  R. Reeve Ingle and
                  Emanuele Bugliarello and
                  Sahar Kazemzadeh and
                  Thomas Mesnard and
                  Ibrahim Alabdulmohsin and
                  Lucas Beyer and
                  Xiaohua Zhai},
  title        = {PaliGemma 2: {A} Family of Versatile VLMs for Transfer},
  journal      = {CoRR},
  volume       = {abs/2412.03555},
  year         = {2024},
  doi          = {10.48550/ARXIV.2412.03555},
  eprinttype    = {arXiv},
  eprint       = {2412.03555},
  timestamp    = {Mon, 13 Jan 2025 21:28:34 +0100},
}

@inproceedings{yoloworld,
  title={YOLO-World: Real-Time Open-Vocabulary Object Detection},
  author={Cheng, Tianheng and Song, Lin and Ge, Yixiao and Liu, Wenyu and Wang, Xinggang and Shan, Ying},
  booktitle={Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR)},
  year={2024}
}

@misc{zhang2022dino,
      title={DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection}, 
      author={Hao Zhang and Feng Li and Shilong Liu and Lei Zhang and Hang Su and Jun Zhu and Lionel M. Ni and Heung-Yeung Shum},
      year={2022},
      eprint={2203.03605},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{li2022dn,
      title={Dn-detr: Accelerate detr training by introducing query denoising},
      author={Li, Feng and Zhang, Hao and Liu, Shilong and Guo, Jian and Ni, Lionel M and Zhang, Lei},
      booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
      pages={13619--13627},
      year={2022}
}

@inproceedings{
      liu2022dabdetr,
      title={{DAB}-{DETR}: Dynamic Anchor Boxes are Better Queries for {DETR}},
      author={Shilong Liu and Feng Li and Hao Zhang and Xiao Yang and Xianbiao Qi and Hang Su and Jun Zhu and Lei Zhang},
      booktitle={International Conference on Learning Representations},
      year={2022},
}

@inproceedings{coco,
  author       = {Tsung-Yi Lin and Michael Maire and Serge J. Belongie and James Hays and Pietro Perona and Deva Ramanan and Piotr Doll{\'a}r and C. Lawrence Zitnick},
  editor       = {David J. Fleet and Tom{\'a}s Pajdla and Bernt Schiele and Tinne Tuytelaars},
  title        = {Microsoft {COCO:} Common Objects in Context},
  booktitle    = {Computer Vision - {ECCV} 2014 - 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part {V}},
  series       = {Lecture Notes in Computer Science},
  volume       = {8693},
  pages        = {740--755},
  publisher    = {Springer},
  year         = {2014},
  doi          = {10.1007/978-3-319-10602-1_48},
  address      = {Cham, Switzerland},
}


@misc{pascal-voc-2012,
  added-at = {2018-09-29T02:23:50.000+0200},
  author = {Everingham, M. and Van Gool, L. and Williams, C. K. I. and Winn, J. and Zisserman, A.},
  howpublished = {http://www.pascal-network.org/challenges/VOC/voc2012/workshop/index.html},
  interhash = {06eda10357dc531658f04086f8dc33c9},
  intrahash = {af3e05b5f98957bd59f03f37fad407c5},
  keywords = {dataset deep_learning object_detection},
  timestamp = {2018-09-29T02:23:50.000+0200},
  title = {The {PASCAL} {V}isual {O}bject {C}lasses {C}hallenge 2012 {(VOC2012)} {R}esults},
  year = {2012},
}

@misc{yolov12,
      title={YOLOv12: Attention-Centric Real-Time Object Detectors}, 
      author={Yunjie Tian and Qixiang Ye and David Doermann},
      year={2025},
      eprint={2502.12524},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
}


% Lit on litter

@INPROCEEDINGS{bottle_detection,
  author={Wang, Jinwang and Guo, Wei and Pan, Ting and Yu, Huai and Duan, Lin and Yang, Wen},
  booktitle={2018 21st International Conference on Information Fusion (FUSION)}, 
  title={Bottle Detection in the Wild Using Low-Altitude Unmanned Aerial Vehicles}, 
  year={2018},
  volume={},
  number={},
  pages={439-444},
  keywords={Unmanned aerial vehicles;Object detection;Image segmentation;Feature extraction;Testing;Proposals;Plastic products;Object Detection;Oriented Bounding Box;Deep Learning;Unmanned Aerial Vehicles},
  doi={10.23919/ICIF.2018.8455565}}

@Article{comparative_study,
AUTHOR = {Córdova, Manuel and Pinto, Allan and Hellevik, Christina Carrozzo and Alaliyat, Saleh Abdel-Afou and Hameed, Ibrahim A. and Pedrini, Helio and Torres, Ricardo da S.},
TITLE = {Litter Detection with Deep Learning: A Comparative Study},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {548},
PubMedID = {35062507},
ISSN = {1424-8220},
DOI = {10.3390/s22020548}
}

@article{small_detection,
  title={Recent advances in small object detection based on deep learning: A review},
  author={Tong, Kang and Wu, Yiquan and Zhou, Fei},
  journal={Image and Vision Computing},
  volume={97},
  pages={103910},
  year={2020},
  publisher={Elsevier}
}

@article{uavs,
  title={Object detection, recognition, and tracking from UAVs using a thermal camera},
  author={Leira, Frederik S and Helgesen, H{\aa}kon Hagen and Johansen, Tor Arne and Fossen, Thor I},
  journal={Journal of Field Robotics},
  volume={38},
  number={2},
  pages={242--267},
  year={2021},
  publisher={Wiley Online Library}
}

@article{kaiming,
  author       = {Kaiming He and
                  Xiangyu Zhang and
                  Shaoqing Ren and
                  Jian Sun},
  title        = {Delving Deep into Rectifiers: Surpassing Human-Level Performance on
                  ImageNet Classification},
  journal      = {CoRR},
  volume       = {abs/1502.01852},
  year         = {2015},
  eprinttype    = {arXiv},
  eprint       = {1502.01852},
  timestamp    = {Wed, 25 Jan 2023 11:01:16 +0100},
}

@inproceedings{tiling,
author = {Unel, Ozge and Ozkalayci, Burak and Cigla, Cevahir},
year = {2019},
booktitle={},
month = {06},
pages = {},
title = {The Power of Tiling for Small Object Detection},
doi = {10.1109/CVPRW.2019.00084}
}

@inproceedings{sahi_detection,
  author       = {Fatih Cagatay Akyon and Onur Altinuc and Sinan Temizel},
  title        = {Slicing Aided Hyper Inference and Fine-Tuning for Small Object Detection},
  booktitle    = {2022 {IEEE} International Conference on Image Processing ({ICIP})},
  address      = {Shanghai, China},
  date         = {2022-10},

  publisher    = {{IEEE}},
  year         = {2022},
  month        = {10},
  doi          = {10.1109/icip46576.2022.9897990},
  timestamp    = {2023-12-12T21:55:40+0100}
}


@misc{rt-detr,
      title={DETRs Beat YOLOs on Real-time Object Detection}, 
      author={Yian Zhao and Wenyu Lv and Shangliang Xu and Jinman Wei and Guanzhong Wang and Qingqing Dang and Yi Liu and Jie Chen},
      year={2024},
      eprint={2304.08069},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
}

@article{taco2020,
    title={TACO: Trash Annotations in Context for Litter Detection},
    author={Pedro F Proença and Pedro Simões},
    journal={arXiv preprint arXiv:2003.06975},
    year={2020}
}

@misc{yolo11,
  author = {Glenn Jocher and Jing Qiu},
  title = {Ultralytics YOLO11},
  version = {11.0.0},
  year = {2024},
  note = {Available at: https://github.com/ultralytics/yolov11},
  orcid = {0000-0001-5950-6979, 0000-0002-7603-6750, 0000-0003-3783-7069},
  license = {AGPL-3.0}
}


% -------------- Litter Detection Review

@INPROCEEDINGS{bdwdataset,
  author={Wang, Jinwang and Guo, Wei and Pan, Ting and Yu, Huai and Duan, Lin and Yang, Wen},
  booktitle={2018 21st International Conference on Information Fusion (FUSION)}, 
  title={Bottle Detection in the Wild Using Low-Altitude Unmanned Aerial Vehicles}, 
  year={2018},
  volume={},
  number={},
  pages={439-444},
  keywords={Unmanned aerial vehicles;Object detection;Image segmentation;Feature extraction;Testing;Proposals;Plastic products;Object Detection;Oriented Bounding Box;Deep Learning;Unmanned Aerial Vehicles},
  doi={10.23919/ICIF.2018.8455565}}

@ARTICLE{rrpn,
  author={Ma, Jianqi and Shao, Weiyuan and Ye, Hao and Wang, Li and Wang, Hong and Zheng, Yingbin and Xue, Xiangyang},
  journal={IEEE Transactions on Multimedia}, 
  title={Arbitrary-Oriented Scene Text Detection via Rotation Proposals}, 
  year={2018},
  volume={20},
  number={11},
  pages={3111-3122},
  keywords={Proposals;Image edge detection;Microsoft Windows;Task analysis;Robustness;Pipelines;Computer architecture;Scene text detection;arbitrary oriented;rotation proposals},
  doi={10.1109/TMM.2018.2818020}}

@article{umgeosurvey,
title = {Optimising beached litter monitoring protocols through aerial imagery},
journal = {Marine Pollution Bulletin},
volume = {131},
pages = {212-217},
year = {2018},
issn = {0025-326X},
doi = {https://doi.org/10.1016/j.marpolbul.2018.04.033},
author = {A. Deidun and A. Gauci and S. Lagorio and F. Galgani},
keywords = {Drones, Monitoring obligations, Marine litter, Optimised protocol, MSFD, MPAs},
abstract = {The monitoring of beached litter along the coast is an onerous obligation enshrined within a number of legislative frameworks (e.g. the MSFD) and which requires substantial human resources in the field. Through this study, we have optimised the protocol for the monitoring of the same litter along coastal stretches within an MPA in the Maltese Islands through aerial drones, with the aim of generating density maps for the beached litter, of assisting in the identification of the same litter and of mainstreaming this type of methodology within national and regional monitoring programmes for marine litter. Concurrent and concomitant in situ monitoring of beached litter enabled us to ground truth the aerial imagery results. Results were finally discussed within the context of current and future MSFD monitoring obligations, with considerations made on possible future policy implications.}
}
@article{trashnet,
  title={Classification of trash for recyclability status},
  author={Yang, Mindy and Thung, Gary},
  journal={CS229 project report},
  volume={2016},
  number={1},
  pages={3},
  year={2016}
}


@misc{kaggleBottlesCans,
	author = {Moez Abid},
	title = {{B}ottles and {C}ans {I}mages --- kaggle.com},
	howpublished = {\url{https://www.kaggle.com/datasets/moezabid/bottles-and-cans}},
	year = {},
	note = {[Accessed 27-02-2025]},
}
@misc{kaggleGarbageClassification,
	author = {},
	title = {{G}arbage {C}lassification (12 classes) --- kaggle.com},
	howpublished = {\url{https://www.kaggle.com/datasets/126ab2c7f7e22add276bc29e44b97f635e3f6a04368afb20130a83518a9056b9}},
	year = {},
	note = {[Accessed 27-02-2025]},
}
@misc{OpenDroneMap,
  author       = {OpenDroneMap Authors},
  title        = {ODM - A command line toolkit to generate maps, point clouds, 3D models and DEMs from drone, balloon or kite images},
  year         = {2017},
  url          = {https://github.com/OpenDroneMap/ODM},
}

@INPROCEEDINGS{superdock,
  author={Niu, Guanchong and Li, Jie and Guo, Sheng and Pun, Man-On and Hou, Leo and Yang, Lujian},
  booktitle={2019 IEEE International Conference on Robotics and Biomimetics (ROBIO)}, 
  title={SuperDock: A Deep Learning-Based Automated Floating Trash Monitoring System}, 
  year={2019},
  volume={},
  number={},
  pages={1035-1040},
  keywords={UAV;SuperDock;Floating Trash Monitoring;YOLOv3;Transfer Learning.},
  doi={10.1109/ROBIO49542.2019.8961509}}

@article{styrofoam,
author = {Bak, Suho and Hwang, D. and Kim, H. and Yoon, H.},
year = {2019},
month = {08},
pages = {55-58},
title = {DETECTION AND MONITORING OF BEACH LITTER USING UAV IMAGE AND DEEP NEURAL NETWORK},
volume = {XLII-3/W8},
journal = {ISPRS - International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
doi = {10.5194/isprs-archives-XLII-3-W8-55-2019}
}
@misc{tan2020efficientnetrethinkingmodelscaling,
      title={EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks}, 
      author={Mingxing Tan and Quoc V. Le},
      year={2020},
      eprint={1905.11946},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}
@ARTICLE{segnet,
  author={Badrinarayanan, Vijay and Kendall, Alex and Cipolla, Roberto},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation}, 
  year={2017},
  volume={39},
  number={12},
  pages={2481-2495},
  keywords={Decoding;Neural networks;Training;Computer architecture;Image segmentation;Semantics;Convolutional codes;Deep convolutional neural networks;semantic pixel-wise segmentation;indoor scenes;road scenes;encoder;decoder;pooling;upsampling},
  doi={10.1109/TPAMI.2016.2644615}}

@INPROCEEDINGS{small_litter_detection,
  author={Schembri, Michael and Seychell, Dylan},
  booktitle={2019 11th International Symposium on Image and Signal Processing and Analysis (ISPA)}, 
  title={Small Object Detection in Highly Variable Backgrounds}, 
  year={2019},
  volume={},
  number={},
  pages={32-37},
  keywords={Feature extraction;Remote sensing;Object detection;Signal processing algorithms;Heating systems;Detectors;Training;machine vision;object detection;remote sensing;unmanned aerial vehicles},
  doi={10.1109/ISPA.2019.8868719}}


@Article{uavvaste,
AUTHOR = {Kraft, Marek and Piechocki, Mateusz and Ptak, Bartosz and Walas, Krzysztof},
TITLE = {Autonomous, Onboard Vision-Based Trash and Litter Detection in Low Altitude Aerial Images Collected by an Unmanned Aerial Vehicle},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {5},
ARTICLE-NUMBER = {965},
ISSN = {2072-4292},
ABSTRACT = {Public littering and discarded trash are, despite the effort being put to limit it, still a serious ecological, aesthetic, and social problem. The problematic waste is usually localised and picked up by designated personnel, which is a tiresome, time-consuming task. This paper proposes a low-cost solution enabling the localisation of trash and litter objects in low altitude imagery collected by an unmanned aerial vehicle (UAV) during an autonomous patrol mission. The objects of interest are detected in the acquired images and put on the global map using a set of onboard sensors commonly found in typical UAV autopilots. The core object detection algorithm is based on deep, convolutional neural networks. Since the task is domain-specific, a dedicated dataset of images containing objects of interest was collected and annotated. The dataset is made publicly available, and its description is contained in the paper. The dataset was used to test a range of embedded devices enabling the deployment of deep neural networks for inference onboard the UAV. The results of measurements in terms of detection accuracy and processing speed are enclosed, and recommendations for the neural network model and hardware platform are given based on the obtained values. The complete system can be put together using inexpensive, off-the-shelf components, and perform autonomous localisation of discarded trash, relieving human personnel of this burdensome task, and enabling automated pickup planning.},
DOI = {10.3390/rs13050965}
}
@article{tran2022detection,
  title={Detection of bottle marine Debris using unmanned aerial vehicles and machine learning techniques},
  author={Tran, Thi Linh Chi and Huang, Zhi-Cheng and Tseng, Kuo-Hsin and Chou, Ping-Hsien},
  journal={Drones},
  volume={6},
  number={12},
  pages={401},
  year={2022},
  publisher={MDPI}
}
@article{bao2018monitoring,
  title={Monitoring of beach litter by automatic interpretation of unmanned aerial vehicle images using the segmentation threshold method},
  author={Bao, Zhongcong and Sha, Jinming and Li, Xiaomei and Hanchiso, Terefe and Shifaw, Eshetu},
  journal={Marine pollution bulletin},
  volume={137},
  pages={388--398},
  year={2018},
  publisher={Elsevier}
}

@article{mju_waste,
  author       = {Tao Wang and
                  Yuanzheng Cai and
                  Lingyu Liang and
                  Dongyi Ye},
  title        = {A Multi-Level Approach to Waste Object Segmentation},
  journal      = {CoRR},
  volume       = {abs/2007.04259},
  year         = {2020},
  eprinttype    = {arXiv},
  eprint       = {2007.04259},
  timestamp    = {Fri, 28 Aug 2020 11:23:15 +0200},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{fcn,
  title={Fully convolutional networks for semantic segmentation},
  author={Evan Shelhamer and Jonathan Long and Trevor Darrell},
  journal={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2014},
  pages={3431-3440},
}

@article{pspnet,
  title={Pyramid Scene Parsing Network},
  author={Hengshuang Zhao and Jianping Shi and Xiaojuan Qi and Xiaogang Wang and Jiaya Jia},
  journal={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2016},
  pages={6230-6239},
}

@InProceedings{ccnet,
author = {Huang, Zilong and Wang, Xinggang and Huang, Lichao and Huang, Chang and Wei, Yunchao and Liu, Wenyu},
title = {CCNet: Criss-Cross Attention for Semantic Segmentation},
booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
month = {10},
year = {2019}
}

@article{deeplabv3,
  title={Rethinking atrous convolution for semantic image segmentation},
  author={Chen, Liang-Chieh and Papandreou, George and Schroff, Florian and Adam, Hartwig},
  journal={arXiv:1706.05587},
  year={2017}
}

@InProceedings{zerowaste,
    author    = {Bashkirova, Dina and Abdelfattah, Mohamed and Zhu, Ziliang and Akl, James and Alladkani, Fadi and Hu, Ping and Ablavsky, Vitaly and Calli, Berk and Bargal, Sarah Adel and Saenko, Kate},
    title     = {ZeroWaste Dataset: Towards Deformable Object Segmentation in Cluttered Scenes},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {6},
    year      = {2022},
    pages     = {21147-21157}
}

@INPROCEEDINGS{tridentnet,
  author={Li, Yanghao and Chen, Yuntao and Wang, Naiyan and Zhang, Zhao-Xiang},
  booktitle={2019 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={Scale-Aware Trident Networks for Object Detection}, 
  year={2019},
  volume={},
  number={},
  pages={6053-6062},
  keywords={Feature extraction;Training;Detectors;Object detection;Proposals;Semantics;Computer architecture},
  doi={10.1109/ICCV.2019.00615}}

@Article{plastopol,
AUTHOR = {Córdova, Manuel and Pinto, Allan and Hellevik, Christina Carrozzo and Alaliyat, Saleh Abdel-Afou and Hameed, Ibrahim A. and Pedrini, Helio and Torres, Ricardo da S.},
TITLE = {Litter Detection with Deep Learning: A Comparative Study},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {548},
PubMedID = {35062507},
ISSN = {1424-8220},
ABSTRACT = {Pollution in the form of litter in the natural environment is one of the great challenges of our times. Automated litter detection can help assess waste occurrences in the environment. Different machine learning solutions have been explored to develop litter detection tools, thereby supporting research, citizen science, and volunteer clean-up initiatives. However, to the best of our knowledge, no work has investigated the performance of state-of-the-art deep learning object detection approaches in the context of litter detection. In particular, no studies have focused on the assessment of those methods aiming their use in devices with low processing capabilities, e.g., mobile phones, typically employed in citizen science activities. In this paper, we fill this literature gap. We performed a comparative study involving state-of-the-art CNN architectures (e.g., Faster RCNN, Mask-RCNN, EfficientDet, RetinaNet and YOLO-v5), two litter image datasets and a smartphone. We also introduce a new dataset for litter detection, named PlastOPol, composed of 2418 images and 5300 annotations. The experimental results demonstrate that object detectors based on the YOLO family are promising for the construction of litter detection solutions, with superior performance in terms of detection accuracy, processing time, and memory footprint.},
DOI = {10.3390/s22020548}
}

@article{song2022assessment,
  title={Assessment of marine debris on hard-to-reach places using unmanned aerial vehicles and segmentation models based on a deep learning approach},
  author={Song, Kyounghwan and Jung, Jung-Yeul and Lee, Seung Hyun and Park, Sanghyun and Yang, Yunjung},
  journal={Sustainability},
  volume={14},
  number={14},
  pages={8311},
  year={2022},
  publisher={MDPI}
}

@Article{haida,
AUTHOR = {Liao, Yu-Hsien and Juang, Jih-Gau},
TITLE = {Real-Time UAV Trash Monitoring System},
JOURNAL = {Applied Sciences},
VOLUME = {12},
YEAR = {2022},
NUMBER = {4},
ARTICLE-NUMBER = {1838},
ISSN = {2076-3417},
ABSTRACT = {This study proposes a marine trash detection system based on unmanned aerial vehicles (UAVs) and aims to replace manpower with UAVs to detect marine trash efficiently and provide information to government agencies regarding real-time trash pollution. Internet technology and computer–machine interaction were applied in this study, which involves the deployment of a marine trash detection system on a drone’s onboard computer for real-time calculations. Images of marine trash were provided to train a modified YOLO model (You Look Only Once networks). The UAV was shown to be able to fly along a predefined path and detect trash in coastal areas. The detection results were sent to a data streaming platform for data processing and analysis. The Kafka message queuing system and the Mongo database were used for data transmission and analysis. It was shown that a real-time drone map monitoring station can be built up at any place where mobile communication is accessible. While a UAV is automatically controlled by an onboard computer, it can also be controlled through a remote station. It was shown that the proposed system can perform data analysis and transmit heatmaps of coastal trash information to a remote site. From the heatmaps, government agencies can use trash categories and locations to take further action.},
DOI = {10.3390/app12041838}
}
@misc{franklin2020cloud,
  author       = {Franklin, Dustin and Hariharapura, Shubha S. and Todd, Stephanie},
  title        = {Bringing Cloud-Native Agility to Edge AI Devices with the NVIDIA Jetson Xavier NX Developer Kit},
  year         = {2020},
  howpublished = {\url{https://developer.nvidia.com/blog/bringing-cloud-native-agility-to-edge-ai-with-jetson-xavier-nx/}},
  note         = {Accessed: 2025-03-13}
}


@article{bangladeshi,
author = {Das, Dhrubajyoti and Kaushik, Deb and Sayeed, Taufique and Dhar, Pranab and Shimamura, Tetsuya},
year = {2023},
month = {09},
pages = {97549-97566},
title = {Outdoor Trash Detection in Natural Environment Using a Deep Learning Model},
volume = {VOLUME 11},
journal = {IEEE Access},
doi = {10.1109/access.2023.3313166}
}

@Article{beach_litter,
AUTHOR = {Pfeiffer, Roland and Valentino, Gianluca and D’Amico, Sebastiano and Piroddi, Luca and Galone, Luciano and Calleja, Stefano and Farrugia, Reuben A. and Colica, Emanuele},
TITLE = {Use of UAVs and Deep Learning for Beach Litter Monitoring},
JOURNAL = {Electronics},
VOLUME = {12},
YEAR = {2023},
NUMBER = {1},
ARTICLE-NUMBER = {198},
ISSN = {2079-9292},
DOI = {10.3390/electronics12010198}
}

@article{trashnet_highscool, place={Houston, USA}, title={TrashNet: An object detection model that classifies images of trash in real-time}, volume={13},  DOI={10.47611/jsrhs.v13i2.6533}, number={2}, journal={Journal of Student Research}, author={Veeravadivel Santhanalakshmi, Veerrohit and Nguyen, Hieu}, year={2024}, month={5} }
@inproceedings{aral2018classification,
  title={Classification of trashnet dataset based on deep learning models},
  author={Aral, Rahmi Arda and Keskin, {\c{S}}eref Recep and Kaya, Mahmut and Hac{\i}{\"o}mero{\u{g}}lu, Murat},
  booktitle={2018 IEEE International Conference on Big Data (Big Data)},
  pages={2058--2062},
  year={2018},
  organization={IEEE}
}
@article{ma2024dsyolo,
  title={DSYOLO-trash: An attention mechanism-integrated and object tracking algorithm for solid waste detection},
  author={Ma, Wanqi and Chen, Hong and Zhang, Wenkang and Huang, Han and Wu, Jian and Peng, Xu and Sun, Qingqing},
  journal={Waste Management},
  volume={178},
  pages={46--56},
  year={2024},
  publisher={Elsevier}
}


@INPROCEEDINGS{detect_litter,
  author={Pisani, Daniel and Seychell, Dylan},
  booktitle={2024 IEEE 22nd Mediterranean Electrotechnical Conference (MELECON)}, 
  title={Detecting Litter From Aerial Imagery Using the SODA Dataset}, 
  year={2024},
  volume={},
  number={},
  pages={897-902},
  keywords={Meters;YOLO;Training;Merging;Habitats;Glass;Autonomous aerial vehicles;Aerial Imagery;Litter Detection;Computer Vision;Drones;YOLOv8},
  doi={10.1109/MELECON56669.2024.10608507}}

@INPROCEEDINGS{soda_dataset,
  author={Pisani, Daniel and Seychell, Dylan and Debono, Carl James and Schembri, Michael},
  booktitle={2024 IEEE International Conference on Image Processing (ICIP)}, 
  title={SODA: A Dataset for Small Object Detection in UAV Captured Imagery}, 
  year={2024},
  volume={},
  number={},
  pages={151-157},
  keywords={Training;Annotations;Image processing;Object detection;Machine learning;Glass;Autonomous aerial vehicles;Small Object Detection;Aerial Imagery;YOLOv8},
  doi={10.1109/ICIP51287.2024.10647335}}

@mastersthesis{daniel_thesis,
  title={An Investigation into Small Object Detection from Aerial Imagery},
  author={Pisani, Daniel},
  type={{M.S.} thesis},
  year={2023},
  school={University of Malta}
}
@article{fallati2019anthropogenic,
  title={Anthropogenic Marine Debris assessment with Unmanned Aerial Vehicle imagery and deep learning: A case study along the beaches of the Republic of Maldives},
  author={Fallati, Luca and Polidori, Annalisa and Salvatore, Christian and Saponari, Luca and Savini, Alessandra and Galli, P},
  journal={Science of The Total Environment},
  volume={693},
  pages={133581},
  year={2019},
  publisher={Elsevier}
}
@article{kako2020estimation,
  title={Estimation of plastic marine debris volumes on beaches using unmanned aerial vehicles and image processing based on deep learning},
  author={Kako, Shin'ichiro and Morita, Shohei and Taneda, Tetsuya},
  journal={Marine Pollution Bulletin},
  volume={155},
  pages={111127},
  year={2020},
  publisher={Elsevier}
}

@article{papakonstantinou2021citizen,
  title={A citizen science unmanned aerial system data acquisition protocol and deep learning techniques for the automatic detection and mapping of marine litter concentrations in the coastal zone},
  author={Papakonstantinou, Apostolos and Batsaris, Marios and Spondylidis, Spyros and Topouzelis, Konstantinos},
  journal={Drones},
  volume={5},
  number={1},
  pages={6},
  year={2021},
  publisher={MDPI}
}
@article{takaya2022unmanned,
  title={Unmanned aerial vehicles and deep learning for assessment of anthropogenic marine debris on beaches on an island in a semi-enclosed sea in Japan},
  author={Takaya, Kosuke and Shibata, Atsuki and Mizuno, Yuji and Ise, Takeshi},
  journal={Environmental Research Communications},
  volume={4},
  number={1},
  pages={015003},
  year={2022},
  publisher={IOP Publishing}
}

@INPROCEEDINGS{mask_to_annotation,
  author={Seychell, Dylan and Kenely, Matthew and Bartolo, Matthias and Debono, Carl James and Bugeja, Mark and Sacco, Matthew},
  booktitle={2023 IEEE International Symposium on Multimedia (ISM)}, 
  title={Efficient Automatic Annotation of Binary Masks for Enhanced Training of Computer Vision Models}, 
  year={2023},
  volume={},
  number={},
  pages={256-259},
  keywords={Training;YOLO;Computer vision;Annotations;Computational modeling;Clustering algorithms;Training data;Computer Vision;Data Annotation;Datasets},
  doi={10.1109/ISM59092.2023.00049}}

@inproceedings{colombo2024runtime,
  title={Runtime Verification and AI: Addressing Pragmatic Regulatory Challenges},
  author={Colombo, Christian and Pace, Gordon and Seychell, Dylan},
  booktitle={International Conference on Bridging the Gap between AI and Reality},
  pages={225--241},
  year={2024},
  organization={Springer}
}

@book{kaza2018waste,
  author    = {Silpa Kaza and Lisa C. Yao and Perinaz Bhada-Tata and Frank Van Woerden},
  title     = {What a Waste 2.0: A Global Snapshot of Solid Waste Management to 2050},
  publisher = {World Bank},
  year      = {2018},
  address   = {Washington, DC}
}

@article{hinton_distillation,
  author       = {Geoffrey E. Hinton and
                  Oriol Vinyals and
                  Jeffrey Dean},
  title        = {Distilling the Knowledge in a Neural Network},
  journal      = {CoRR},
  volume       = {abs/1503.02531},
  year         = {2015},
  eprinttype    = {arXiv},
  eprint       = {1503.02531},
  timestamp    = {Mon, 13 Aug 2018 16:48:36 +0200},
}

@article{lupi,
author = {Vapnik, Vladimir and Vashist, Akshay},
year = {2009},
month = {07},
pages = {544-57},
title = {A new learning paradigm: Learning using privileged information},
volume = {22},
journal = {Neural networks : the official journal of the International Neural Network Society},
doi = {10.1016/j.neunet.2009.06.042}
}

@article{Vapnik2015LearningUP,
  title={Learning using privileged information: similarity control and knowledge transfer},
  author={Vladimir Naumovich Vapnik and Rauf Izmailov},
  journal={J. Mach. Learn. Res.},
  year={2015},
  volume={16},
  pages={2023-2049},
}

@inproceedings{lupi_distillation,
  author       = {David Lopez{-}Paz and
                  L{\'{e}}on Bottou and
                  Bernhard Sch{\"{o}}lkopf and
                  Vladimir Vapnik},
  editor       = {Yoshua Bengio and
                  Yann LeCun},
  title        = {Unifying distillation and privileged information},
  booktitle    = {4th International Conference on Learning Representations, {ICLR} 2016,
                  San Juan, Puerto Rico, May 2-4, 2016, Conference Track Proceedings},
  year         = {2016},
  timestamp    = {Thu, 25 Jul 2019 14:25:39 +0200},
}

@inproceedings{lupi_nips,
 author = {Pechyony, Dmitry and Vapnik, Vladimir},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {J. Lafferty and C. Williams and J. Shawe-Taylor and R. Zemel and A. Culotta},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {On the Theory of Learning with Privileged Information},
 volume = {23},
 year = {2010}
}


@INPROCEEDINGS{learning2rank,
  author={Sharmanska, Viktoriia and Quadrianto, Novi and Lampert, Christoph H.},
  booktitle={2013 IEEE International Conference on Computer Vision}, 
  title={Learning to Rank Using Privileged Information}, 
  year={2013},
  volume={},
  number={},
  pages={825-832},
  keywords={Training;Support vector machines;Whales;Seals;Optimization;Computer vision;Vectors;Learning to rank;privileged information during training;object classification},
  doi={10.1109/ICCV.2013.107}}

@misc{learning2rank2,
      title={Learning to Transfer Privileged Information}, 
      author={Viktoriia Sharmanska and Novi Quadrianto and Christoph H. Lampert},
      year={2014},
      eprint={1410.0389},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
}

@article{object_detection_philospy,
  author       = {Boger, T. and Ullman, T.},
  title        = {What is "Where": Physical Reasoning Informs Object Location},
  journal      = {Open Mind (Cambridge)},
  volume       = {7},
  pages        = {130--140},
  year         = {2023},
  month        = {5},
  doi          = {10.1162/opmi_a_00075},
  PMID         = {37416073},
  PMCID        = {PMC10320814}
}

% Itti Saliency Map
@ARTICLE{itti, 
author={L. Itti and C. Koch and E. Niebur}, 
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
title={A model of saliency-based visual attention for rapid scene analysis}, 
year={1998}, 
volume={20}, 
number={11}, 
pages={1254-1259}, 
keywords={computer vision;feature extraction;image recognition;neural nets;target tracking;dynamical neural network;feature extraction;rapid scene analysis;saliency;scene understanding;target detection;topographical saliency map;visual attention;visual search;Biological system modeling;Brain modeling;Computer architecture;Feature extraction;Hardware;Image analysis;Layout;Neural networks;Object detection;Visual system}, 
doi={10.1109/34.730558}, 
ISSN={0162-8828}, 
month={11},
}

@article{itti_ior,
	author = {L. Itti and C. Koch},
	journal = {Nature Reviews Neuroscience},
	number = {3},
	pages = {194--203},
	publisher = {Nature Publishing Group},
	title = {Computational Modelling of Visual Attention},
	volume = {2},
	year = {2001}
}

@article{dpt_large,
  author       = {Ren{\'{e}} Ranftl and
                  Alexey Bochkovskiy and
                  Vladlen Koltun},
  title        = {Vision Transformers for Dense Prediction},
  journal      = {CoRR},
  volume       = {abs/2103.13413},
  year         = {2021},
  eprinttype    = {arXiv},
  eprint       = {2103.13413},
  timestamp    = {Wed, 07 Apr 2021 15:31:46 +0200},
}

@article{deepgaze,
  author       = {Akis Linardos and
                  Matthias K{\"{u}}mmerer and
                  Ori Press and
                  Matthias Bethge},
  title        = {Calibrated prediction in and out-of-domain for state-of-the-art saliency
                  modeling},
  journal      = {CoRR},
  volume       = {abs/2105.12441},
  year         = {2021},
  eprinttype    = {arXiv},
  eprint       = {2105.12441},
  timestamp    = {Tue, 01 Jun 2021 18:07:59 +0200},
}

@misc{depth_anything,
      title={Depth Anything: Unleashing the Power of Large-Scale Unlabeled Data}, 
      author={Lihe Yang and Bingyi Kang and Zilong Huang and Xiaogang Xu and Jiashi Feng and Hengshuang Zhao},
      year={2024},
      eprint={2401.10891},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
}

@article{lupi_classification,
title = {Learning with privileged information for multi-Label classification},
journal = {Pattern Recognition},
volume = {81},
pages = {60-70},
year = {2018},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2018.03.033},
author = {Shangfei Wang and Shiyu Chen and Tanfang Chen and Xiaoxiao Shi},
keywords = {Privileged information, Multi-label classification, Similarity constraints},
abstract = {In this paper, we propose a novel approach for learning multi-label classifiers with the help of privileged information. Specifically, we use similarity constraints to capture the relationship between available information and privileged information, and use ranking constraints to capture the dependencies among multiple labels. By integrating similarity constraints and ranking constraints into the learning process of classifiers, the privileged information and the dependencies among multiple labels are exploited to construct better classifiers during training. A maximum margin classifier is adopted, and an efficient learning algorithm of the proposed method is also developed. We evaluate the proposed method on two applications: multiple object recognition from images with the help of implicit information about object importance conveyed by the list of manually annotated image tags; and multiple facial action unit detection from low-resolution images augmented by high-resolution images. Experimental results demonstrate that the proposed method can effectively take full advantage of privileged information and dependencies among multiple labels for better object recognition and better facial action unit detection.}
}

@article{lupiv3,
  author       = {Viktoriia Sharmanska and
                  Novi Quadrianto and
                  Christoph H. Lampert},
  title        = {Learning to Transfer Privileged Information},
  journal      = {CoRR},
  volume       = {abs/1410.0389},
  year         = {2014},
  eprinttype    = {arXiv},
  eprint       = {1410.0389},
  timestamp    = {Sat, 30 Sep 2023 10:08:02 +0200},
}

@misc{distillation2,
      title={Localization Distillation for Object Detection}, 
      author={Zhaohui Zheng and Rongguang Ye and Qibin Hou and Dongwei Ren and Ping Wang and Wangmeng Zuo and Ming-Ming Cheng},
      year={2022},
      eprint={2204.05957},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
}

@misc{distillation1,
      title={A Comprehensive Review of Knowledge Distillation in Computer Vision}, 
      author={Gousia Habib and Tausifa jan Saleem and Sheikh Musa Kaleem and Tufail Rouf and Brejesh Lall},
      year={2024},
      eprint={2404.00936},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
}
@misc{ssdlite,
      title={MobileNetV2: Inverted Residuals and Linear Bottlenecks}, 
      author={Mark Sandler and Andrew Howard and Menglong Zhu and Andrey Zhmoginov and Liang-Chieh Chen},
      year={2019},
      eprint={1801.04381},
      archivePrefix={arXiv},
      primaryClass={cs.CV}, 
}

@article{mobilenet,
  author       = {Andrew G. Howard and
                  Menglong Zhu and
                  Bo Chen and
                  Dmitry Kalenichenko and
                  Weijun Wang and
                  Tobias Weyand and
                  Marco Andreetto and
                  Hartwig Adam},
  title        = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
                  Applications},
  journal      = {CoRR},
  volume       = {abs/1704.04861},
  year         = {2017},
  eprinttype    = {arXiv},
  eprint       = {1704.04861},
  timestamp    = {Thu, 27 May 2021 16:20:51 +0200},
}

@phdthesis{ssdlite_diagram,
author = {Le, Cong},
year = {2021},
month = {06},
pages = {},
title = {Real-time hair and clothes segmentation on mobile devices},
doi = {10.13140/RG.2.2.16236.08325},
school={Vietnam National University, Hanoi -- University of Engineering and Technology}
}

@article{mobilenetv3,
  author       = {Andrew Howard and
                  Mark Sandler and
                  Grace Chu and
                  Liang{-}Chieh Chen and
                  Bo Chen and
                  Mingxing Tan and
                  Weijun Wang and
                  Yukun Zhu and
                  Ruoming Pang and
                  Vijay Vasudevan and
                  Quoc V. Le and
                  Hartwig Adam},
  title        = {Searching for MobileNetV3},
  journal      = {CoRR},
  volume       = {abs/1905.02244},
  year         = {2019},
  eprinttype    = {arXiv},
  eprint       = {1905.02244},
  timestamp    = {Thu, 27 May 2021 16:20:51 +0200},
}

@article{fasterrcnn_diagram,
author = {Wang, Xingzheng and Wei, Guoyao and Chen, Songwei and Liu, Jiehao},
year = {2023},
month = {06},
pages = {1-24},
title = {An efficient weakly semi-supervised method for object automated annotation},
volume = {83},
journal = {Multimedia Tools and Applications},
doi = {10.1007/s11042-023-15305-0}
}

@article{spotlight,
title = {Multiple Spotlights of Attentional Selection in Human Visual Cortex},
journal = {Neuron},
volume = {42},
number = {4},
pages = {677-686},
year = {2004},
issn = {0896-6273},
doi = {https://doi.org/10.1016/S0896-6273(04)00263-6},
author = {Stephanie A McMains and David C Somers},
abstract = {Spatially directed attention strongly enhances visual perceptual processing. The metaphor of the “spotlight” has long been used to describe spatial attention; however, there has been considerable debate as to whether spatial attention must be unitary or may be split between discrete regions of space. This question was addressed here through functional MR imaging of human subjects as they performed a task that required simultaneous attention to two briefly displayed and masked targets at locations separated by distractor stimuli. These data reveal retinotopically specific enhanced activation in striate and extrastriate visual cortical representations of the two attended stimuli and no enhancement at the intervening representation of distractor stimuli. This finding of two spotlights was obtained within a single cortical hemisphere and across the two hemispheres. This provides direct evidence that spatial attention can select, in parallel, multiple low-level perceptual representations.}
}

@ARTICLE{lab2wild,
  author={Makantasis, Konstantinos and Pinitas, Kosmas and Liapis, Antonios and Yannakakis, Georgios N.},
  journal={IEEE Transactions on Affective Computing}, 
  title={From the Lab to the Wild: Affect Modeling Via Privileged Information}, 
  year={2024},
  volume={15},
  number={2},
  pages={380-392},
  keywords={Computational modeling;Visualization;Sensors;Data models;Brain modeling;Testing;Emotion recognition;Affect modelling;arousal;machine learning;privileged information;physiology;pixels;valence},
  doi={10.1109/TAFFC.2023.3265072}}

@misc{adam_optimizer,
      title={Adam: A Method for Stochastic Optimization}, 
      author={Diederik P. Kingma and Jimmy Ba},
      year={2017},
      eprint={1412.6980},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}

@article{sgd_optimizer,
  author       = {Sebastian Ruder},
  title        = {An overview of gradient descent optimization algorithms},
  journal      = {CoRR},

  year         = {2016},
  eprinttype    = {arXiv},
  eprint       = {1609.04747},
  timestamp    = {Mon, 13 Aug 2018 16:48:10 +0200},
}

@article{min_max_normalisation,
  author       = {S. Gopal Krishna Patro and
                  Kishore Kumar Sahu},
  title        = {Normalization: {A} Preprocessing Stage},
  journal      = {CoRR},

  year         = {2015},
  eprinttype    = {arXiv},
  eprint       = {1503.06462},
  timestamp    = {Mon, 13 Aug 2018 16:48:14 +0200},
}

@article{nms,
  author       = {Jan Hendrik Hosang and
                  Rodrigo Benenson and
                  Bernt Schiele},
  title        = {Learning non-maximum suppression},
  journal      = {CoRR},
  volume       = {abs/1705.02950},
  year         = {2017},
  eprinttype    = {arXiv},
  eprint       = {1705.02950},
  timestamp    = {Mon, 13 Aug 2018 16:46:59 +0200},
}

@misc{elbow_point,
      title={A More Precise Elbow Method for Optimum K-means Clustering}, 
      author={Indra Herdiana and M Alfin Kamal and Triyani and Mutia Nur Estri and Renny},
      year={2025},
      eprint={2502.00851},
      archivePrefix={arXiv},
      primaryClass={stat.ME},
}

@software{rf-detr,
  author = {Robinson, Isaac and Robicheaux, Peter and Popov, Matvei},
  license = {Apache-2.0},
  title = {RF-DETR},
  howpublished = {\url{https://github.com/roboflow/rf-detr}},
  year = {2025},
  note = {SOTA Real-Time Object Detection Model}
}

%%============================================================================%%
%% while using chicago reference style, both abbreviated and expanded form of %%
%% author name format is acceptable. Refer below example for expanded form    %%
%%============================================================================%%

%%  author		= "{Cameron, Deborah}", - single author
%%  author		= "{Saito, Yukio} and {Hyuga, Hiroyuki}", - double author 

%%======================================%%
%% Example for author names with suffix %%
%%======================================%%

%%  author		= "{Price, R. A. Jr} and {Curry, N. {III}} and McCann, K. E. and 
%%					Fielding, J. L. and {Abercrombie, E. Jr}",
