{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Notebook for Generating Privileged Information for Object Detection Datasets</h1>\n",
    "<h2>Matthias Bartolo</h2>\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_datasets = False # True\n",
    "if download_datasets:\n",
    "    import os\n",
    "    import json\n",
    "    from roboflow import Roboflow\n",
    "\n",
    "    HOME = os.getcwd()\n",
    "    # Go back one directory to the root of the project\n",
    "    HOME = os.path.dirname(HOME)\n",
    "    print(\"Downloading datasets to: \", os.path.join(HOME, 'datasets'))\n",
    "\n",
    "    if not os.path.isdir(os.path.join(HOME, 'datasets')):\n",
    "        os.mkdir(os.path.join(HOME, 'datasets'))\n",
    "    os.chdir(os.path.join(HOME, 'datasets'))\n",
    "\n",
    "    ########################################################## ROBOFLOW ##########################################################\n",
    "    # SODA Dataset\n",
    "    rf = Roboflow(api_key=\"nyynHs3oneLLx01D04rC\")\n",
    "    # project = rf.workspace(\"soda-dataset\").project(\"01m-all\")\n",
    "    # version = project.version(1)\n",
    "    # dataset = version.download(\"coco\")\n",
    "\n",
    "    project = rf.workspace(\"soda-dataset\").project(\"soda-litter-dataset-all\")\n",
    "    version = project.version(1)\n",
    "    dataset = version.download(\"coco\")\n",
    "\n",
    "    project = rf.workspace(\"soda-dataset\").project(\"soda-litter-dataset-all\")\n",
    "    version = project.version(2)\n",
    "    dataset = version.download(\"coco\")\n",
    "\n",
    "    # project = rf.workspace(\"bottles-in-the-wild\").project(\"bottles_wild\")\n",
    "    # version = project.version(1)\n",
    "    # dataset = version.download(\"coco\")\n",
    "\n",
    "    # project = rf.workspace(\"mcast\").project(\"uavvaste-avcle\")\n",
    "    # version = project.version(1)\n",
    "    # dataset = version.download(\"coco\")\n",
    "\n",
    "    # COCO Dataset from Roboflow (images resized to 1280x1280)\n",
    "    # project = rf.workspace(\"microsoft\").project(\"coco\")\n",
    "    # version = project.version(9)\n",
    "    # dataset = version.download(\"coco\")\n",
    "\n",
    "    # project = rf.workspace(\"jacob-solawetz\").project(\"pascal-voc-2012\")\n",
    "    # version = project.version(1)\n",
    "    # dataset = version.download(\"coco\")\n",
    "\n",
    "    ########################################################## ROBOFLOW ##########################################################\n",
    "\n",
    "    # Ensure correct folder structure\n",
    "    directories = ['train', 'valid', 'test']\n",
    "    # Change the directories to get the full path\n",
    "    directories = [os.path.join(dataset.location, directory) for directory in directories]\n",
    "\n",
    "    for directory in directories:\n",
    "        os.makedirs(f'{directory}/images', exist_ok=True)  # Create 'images' subfolder\n",
    "\n",
    "    # Move images to corresponding 'images' subfolders while keeping annotations in the main split folder\n",
    "    for directory in directories:\n",
    "        image_dir = os.path.join(dataset.location, directory)  # Original dataset directory\n",
    "        dest_image_dir = f'{directory}/images'  # Destination images folder\n",
    "\n",
    "        annotation_file = os.path.join(image_dir, \"_annotations.coco.json\")\n",
    "        new_annotation_path = os.path.join(directory, \"_annotations.coco.json\")\n",
    "\n",
    "        for file_name in os.listdir(image_dir):  # Iterate over files in the dataset split\n",
    "            src_path = os.path.join(image_dir, file_name)\n",
    "\n",
    "            if file_name.endswith('.jpg') or file_name.endswith('.png'):  # Move images\n",
    "                dest_path = os.path.join(dest_image_dir, file_name)\n",
    "            elif file_name == \"_annotations.coco.json\":  # Keep annotations in the main split folder\n",
    "                dest_path = new_annotation_path\n",
    "            else:\n",
    "                continue  # Ignore other file types\n",
    "\n",
    "            if os.path.isfile(src_path):  # Ensure it's a file before moving\n",
    "                os.rename(src_path, dest_path)\n",
    "\n",
    "        # Update _annotations.coco.json to reflect the new image paths\n",
    "        if os.path.isfile(new_annotation_path):\n",
    "            with open(new_annotation_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            for image in data[\"images\"]:\n",
    "                image[\"file_name\"] = f\"{image['file_name']}\"  # Update path in annotation\n",
    "\n",
    "            with open(new_annotation_path, 'w') as f:\n",
    "                json.dump(data, f, indent=4)  # Save the updated JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared imports\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Paths\n",
    "yolo_dataset_path = \"../datasets/SODA-Litter-Dataset-All-2/\"  # Base path for your COCO dataset\n",
    "output_base_path = \"../datasets/SODA-Litter-Dataset-All-2/\"   # Base path for saving saliency map images\n",
    "images_path='images/' # Path to the images in each dataset subfolder\n",
    "number_of_classes = 6  # Number of classes in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saliency Map Generation (Itti Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import SaRa.saraRC1 as sara # Do not change the home directory for this one\n",
    "\n",
    "GENERATORS = ['itti', 'deepgaze']  # Available saliency generators\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "def generate_saliency_maps(yolo_dataset_path, output_base_path, generator='itti', images_path='images'):\n",
    "    \"\"\"\n",
    "    Generate and save saliency map images using the SaRa library for a YOLO dataset.\n",
    "\n",
    "    Args:\n",
    "        yolo_dataset_path (str): Path to the dataset with train, test, valid folders.\n",
    "        output_base_path (str): Path to save the saliency map images.\n",
    "        generator (str): Saliency map generator ('itti' or 'deepgaze').\n",
    "    \"\"\"\n",
    "    if generator not in GENERATORS:\n",
    "        raise ValueError(f\"Invalid generator '{generator}'. Must be one of {GENERATORS}.\")\n",
    "\n",
    "    for subset in [\"train\", \"test\", \"valid\"]:\n",
    "        input_folder = os.path.join(yolo_dataset_path, subset, images_path)\n",
    "        output_folder = os.path.join(output_base_path, subset, f\"Saliency_{generator}\")\n",
    "\n",
    "        # Check if input folder exists\n",
    "        if not os.path.exists(input_folder):\n",
    "            print(f\"Skipping {subset} as directory {input_folder} does not exist.\")\n",
    "            continue\n",
    "\n",
    "        # Create the output folder if it doesn't exist\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        for image_file in os.listdir(input_folder):\n",
    "            # Process only image files\n",
    "            if image_file.endswith(('.jpg', '.png', '.jpeg')):\n",
    "                image_path = os.path.join(input_folder, image_file)\n",
    "                output_image_path = os.path.join(output_folder, image_file)\n",
    "\n",
    "                # Read the image\n",
    "                image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                if image is None:\n",
    "                    print(f\"Could not read image {image_path}\")\n",
    "                    continue\n",
    "\n",
    "                # Apply saliency map generation\n",
    "                image_np = np.array(image)\n",
    "                sara_image = image_np.copy()\n",
    "                sara.reset()\n",
    "                \n",
    "                \n",
    "                saliency_map = sara.return_saliency(sara_image, generator=generator)                \n",
    "\n",
    "                # Save the processed image\n",
    "                cv2.imwrite(output_image_path, saliency_map)\n",
    "                print(f\"Saved saliency map image to {output_image_path}\")\n",
    "\n",
    "# Choose saliency generator and generate saliency maps\n",
    "generator = 'itti'  # Change to 'deepgaze' as needed\n",
    "generate_saliency_maps(yolo_dataset_path, output_base_path, generator=generator, images_path=images_path)\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "# Save the duration to a file\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "with open(f\"results/saliency_map_generation_{generator}.txt\", \"w\") as f:\n",
    "    f.write(f\"Duration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saliency Map Generation (DeepGaze IIE Model)\n",
    "Note: This technique takes a long time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import SaRa.saraRC1 as sara\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "GENERATORS = ['itti', 'deepgaze']  # Available saliency generators\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "def generate_saliency_maps(yolo_dataset_path, output_base_path, generator='itti', images_path='images'):\n",
    "    \"\"\"\n",
    "    Generate and save saliency map images using the SaRa library for a YOLO dataset.\n",
    "\n",
    "    Args:\n",
    "        yolo_dataset_path (str): Path to the dataset with train, test, valid folders.\n",
    "        output_base_path (str): Path to save the saliency map images.\n",
    "        generator (str): Saliency map generator ('itti' or 'deepgaze').\n",
    "    \"\"\"\n",
    "    if generator not in GENERATORS:\n",
    "        raise ValueError(f\"Invalid generator '{generator}'. Must be one of {GENERATORS}.\")\n",
    "\n",
    "    for subset in [\"train\", \"test\", \"valid\"]:\n",
    "        input_folder = os.path.join(yolo_dataset_path, subset, images_path)\n",
    "        output_folder = os.path.join(output_base_path, subset, f\"Saliency_{generator}\")\n",
    "\n",
    "        # Check if input folder exists\n",
    "        if not os.path.exists(input_folder):\n",
    "            print(f\"Skipping {subset} as directory {input_folder} does not exist.\")\n",
    "            continue\n",
    "\n",
    "        # Create the output folder if it doesn't exist\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        for image_file in os.listdir(input_folder):\n",
    "            # Process only image files\n",
    "            if image_file.endswith(('.jpg', '.png', '.jpeg')):\n",
    "                image_path = os.path.join(input_folder, image_file)\n",
    "                output_image_path = os.path.join(output_folder, image_file)\n",
    "\n",
    "                # Read the image\n",
    "                image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                if image is None:\n",
    "                    print(f\"Could not read image {image_path}\")\n",
    "                    continue\n",
    "\n",
    "                # Apply saliency map generation\n",
    "                image_np = np.array(image)\n",
    "                sara_image = image_np.copy()\n",
    "                sara.reset()\n",
    "                \n",
    "                \n",
    "                saliency_map = sara.return_saliency(sara_image, generator=generator)                \n",
    "\n",
    "                # Save the processed image\n",
    "                cv2.imwrite(output_image_path, saliency_map)\n",
    "                print(f\"Saved saliency map image to {output_image_path}\")\n",
    "\n",
    "# Choose saliency generator and generate saliency maps\n",
    "generator = 'deepgaze'  # Change to 'deepgaze' as needed\n",
    "generate_saliency_maps(yolo_dataset_path, output_base_path, generator=generator, images_path=images_path)\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "# Save the duration to a file\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "with open(f\"results/saliency_map_generation_{generator}.txt\", \"w\") as f:\n",
    "    f.write(f\"Duration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depth Map Generation (Depth Anything Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "def generate_depth_maps(yolo_dataset_path, output_base_path, model_name, images_path='images', save_dir='Depth_Anything'):\n",
    "    \"\"\"\n",
    "    Generate and save depth estimation images for a YOLO dataset.\n",
    "\n",
    "    Args:\n",
    "        yolo_dataset_path (str): Path to the dataset with train, test, valid folders.\n",
    "        output_base_path (str): Path to save the depth images.\n",
    "        model_name (str): Hugging Face model for depth estimation.\n",
    "        images_path (str): Path within each subset for the images.\n",
    "    \"\"\"\n",
    "    if not model_name:\n",
    "        raise ValueError(\"A model_name must be provided for depth estimation.\")\n",
    "\n",
    "    # Initialize depth estimation pipeline\n",
    "    pipe = pipeline(task=\"depth-estimation\", model=model_name, device=device)\n",
    "\n",
    "    for subset in [\"train\", \"test\", \"valid\"]:\n",
    "        input_folder = os.path.join(yolo_dataset_path, subset, images_path)\n",
    "        output_folder = os.path.join(output_base_path, subset, f\"Depth_{save_dir.replace('/', '_')}\")\n",
    "\n",
    "        # Check if input folder exists\n",
    "        if not os.path.exists(input_folder):\n",
    "            print(f\"Skipping {subset} as directory {input_folder} does not exist.\")\n",
    "            continue\n",
    "\n",
    "        # Create the output folder if it doesn't exist\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        for image_file in os.listdir(input_folder):\n",
    "            # Process only image files\n",
    "            if image_file.endswith(('.jpg', '.png', '.jpeg')):\n",
    "                image_path = os.path.join(input_folder, image_file)\n",
    "                output_image_path = os.path.join(output_folder, image_file)\n",
    "\n",
    "                # Apply depth estimation\n",
    "                try:\n",
    "                    depth_map = pipe(image_path)[\"depth\"]\n",
    "                    processed_image = np.array(depth_map)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error generating depth map for {image_path} with model '{model_name}': {e}\")\n",
    "                    continue\n",
    "\n",
    "                # Save the processed image\n",
    "                cv2.imwrite(output_image_path, processed_image)\n",
    "                print(f\"Saved depth map image to {output_image_path}\")\n",
    "\n",
    "# Generate depth maps\n",
    "model_name = \"LiheYoung/depth-anything-small-hf\"  # Model for depth estimation\n",
    "generate_depth_maps(yolo_dataset_path, output_base_path, model_name=model_name, images_path=images_path)\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "# Save the duration to a file\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "with open(f\"results/depth_map_generation_Depth_Anything.txt\", \"w\") as f:\n",
    "    f.write(f\"Duration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depth Map Generation (DPT-Large Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "def generate_depth_maps(yolo_dataset_path, output_base_path, model_name, images_path='images', save_dir='Depth_Anything'):\n",
    "    \"\"\"\n",
    "    Generate and save depth estimation images for a YOLO dataset.\n",
    "\n",
    "    Args:\n",
    "        yolo_dataset_path (str): Path to the dataset with train, test, valid folders.\n",
    "        output_base_path (str): Path to save the depth images.\n",
    "        model_name (str): Hugging Face model for depth estimation.\n",
    "        images_path (str): Path within each subset for the images.\n",
    "    \"\"\"\n",
    "    if not model_name:\n",
    "        raise ValueError(\"A model_name must be provided for depth estimation.\")\n",
    "\n",
    "    # Initialize depth estimation pipeline\n",
    "    pipe = pipeline(task=\"depth-estimation\", model=model_name, device=device)\n",
    "\n",
    "    for subset in [\"train\", \"test\", \"valid\"]:\n",
    "        input_folder = os.path.join(yolo_dataset_path, subset, images_path)\n",
    "        output_folder = os.path.join(output_base_path, subset, f\"Depth_{save_dir.replace('/', '_')}\")\n",
    "\n",
    "        # Check if input folder exists\n",
    "        if not os.path.exists(input_folder):\n",
    "            print(f\"Skipping {subset} as directory {input_folder} does not exist.\")\n",
    "            continue\n",
    "\n",
    "        # Create the output folder if it doesn't exist\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        for image_file in os.listdir(input_folder):\n",
    "            # Process only image files\n",
    "            if image_file.endswith(('.jpg', '.png', '.jpeg')):\n",
    "                image_path = os.path.join(input_folder, image_file)\n",
    "                output_image_path = os.path.join(output_folder, image_file)\n",
    "\n",
    "                # Apply depth estimation\n",
    "                try:\n",
    "                    depth_map = pipe(image_path)[\"depth\"]\n",
    "                    processed_image = np.array(depth_map)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error generating depth map for {image_path} with model '{model_name}': {e}\")\n",
    "                    continue\n",
    "\n",
    "                # Save the processed image\n",
    "                cv2.imwrite(output_image_path, processed_image)\n",
    "                print(f\"Saved depth map image to {output_image_path}\")\n",
    "\n",
    "# Generate depth maps\n",
    "model_name = \"Intel/dpt-large\"  # Model for depth estimation\n",
    "generate_depth_maps(yolo_dataset_path, output_base_path, model_name=model_name, images_path=images_path, save_dir='DPT_Large')\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "# Save the duration to a file\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "with open(f\"results/depth_map_generation_DPT_Large.txt\", \"w\") as f:\n",
    "    f.write(f\"Duration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram of Oriented Gradients (HOG) Generation\n",
    "Note: This technique takes a long time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "def generate_hog_maps(yolo_dataset_path, output_base_path, images_path='images'):\n",
    "    \"\"\"\n",
    "    Generate and save HOG feature images for a YOLO dataset.\n",
    "\n",
    "    Args:\n",
    "        yolo_dataset_path (str): Path to the dataset with train, test, valid folders.\n",
    "        output_base_path (str): Path to save the HOG feature images.\n",
    "        images_path (str): Path within each subset for the images.\n",
    "    \"\"\"\n",
    "    for subset in [\"train\", \"test\", \"valid\"]:\n",
    "        input_folder = os.path.join(yolo_dataset_path, subset, images_path)\n",
    "        output_folder = os.path.join(output_base_path, subset, \"HoG_Features\")\n",
    "\n",
    "        # Check if input folder exists\n",
    "        if not os.path.exists(input_folder):\n",
    "            print(f\"Skipping {subset} as directory {input_folder} does not exist.\")\n",
    "            continue\n",
    "\n",
    "        # Create the output folder if it doesn't exist\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        for image_file in os.listdir(input_folder):\n",
    "            # Process only image files\n",
    "            if image_file.endswith(('.jpg', '.png', '.jpeg')):\n",
    "                image_path = os.path.join(input_folder, image_file)\n",
    "                output_image_path = os.path.join(output_folder, image_file)\n",
    "\n",
    "                # Read the image\n",
    "                image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "                if image is None:\n",
    "                    print(f\"Could not read image {image_path}\")\n",
    "                    continue\n",
    "\n",
    "                # Compute HOG features and visualization\n",
    "                features, hog_image = hog(\n",
    "                        image, \n",
    "                        pixels_per_cell=(8, 8),  # Standard pixel size\n",
    "                        cells_per_block=(2, 2),  # Block size for normalization\n",
    "                        visualize=True, \n",
    "                        block_norm='L2-Hys',  # Normalize the block for better detection\n",
    "                    )\n",
    "                processed_image = (hog_image * 255).astype(np.uint8)  # Scale to 8-bit image\n",
    "            \n",
    "\n",
    "                # Save the processed image\n",
    "                cv2.imwrite(output_image_path, processed_image)\n",
    "                print(f\"Saved HoG feature image to {output_image_path}\")\n",
    "\n",
    "# Generate HOG maps\n",
    "generate_hog_maps(yolo_dataset_path, output_base_path, images_path)\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "# Save the duration to a file\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "with open(\"results/hog_map_generation.txt\", \"w\") as f:\n",
    "    f.write(f\"Duration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Functions for Visual Descriptors\n",
    "\n",
    "**Local descriptors** that take into consideration each one of the image pixels separately. Local descriptors indicate the magnitude of local features for each one of image pixels. \n",
    "\n",
    "**Global descriptors** that are capable to emphasize pixels with high uniqueness compared to the rest of the image. To achieve this they indicate how different local features for a specific pixel are, in relation with the same features of all other image pixels. \n",
    "\n",
    "**Window descriptors** that compare local features of a pixel with the same features of its neighboring pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.ndimage import generic_filter\n",
    "\n",
    "block_size = 4  # Block size, i.e., a 4x4 block kernel\n",
    "\n",
    "def generate_pyramids(feature_map, bSize=block_size):\n",
    "    \"\"\"\n",
    "    Generate 4 pyramid levels from the input feature map.\n",
    "    \n",
    "    Args:\n",
    "        feature_map (np.ndarray): The input feature map.\n",
    "        bSize (int): Block size for initial resizing.\n",
    "        \n",
    "    Returns:\n",
    "        pyr1, pyr2, pyr3, pyr4 (np.ndarray): The four pyramid levels.\n",
    "    \"\"\"\n",
    "    # Resize the feature map\n",
    "    newx = feature_map.shape[1] // bSize\n",
    "    newy = feature_map.shape[0] // bSize\n",
    "    blockImg = cv2.resize(feature_map, (newx, newy), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # Generate pyramid levels\n",
    "    pyr1 = blockImg\n",
    "    pyr2 = cv2.pyrDown(pyr1)\n",
    "    pyr3 = cv2.pyrDown(pyr2)\n",
    "    pyr4 = cv2.pyrDown(pyr3)\n",
    "    \n",
    "    return pyr1, pyr2, pyr3, pyr4\n",
    "\n",
    "\n",
    "def process_pyramid_levels(pyr1, pyr2, pyr3, pyr4, bSize=block_size):\n",
    "    \"\"\"\n",
    "    Process pyramid levels by resizing, blending, and returning the final descriptor map.\n",
    "    \n",
    "    Args:\n",
    "        pyr1, pyr2, pyr3, pyr4 (np.ndarray): The four pyramid levels.\n",
    "        \n",
    "    Returns:\n",
    "        descriptor_map (np.ndarray): The blended descriptor map.\n",
    "    \"\"\"\n",
    "    # Resize pyramid levels back to pyr1's size\n",
    "    pyr2R = cv2.resize(pyr2, (pyr1.shape[1], pyr1.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
    "    pyr3R = cv2.resize(pyr3, (pyr1.shape[1], pyr1.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
    "    pyr4R = cv2.resize(pyr4, (pyr1.shape[1], pyr1.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    # Blend the pyramid levels\n",
    "    tempPyr = cv2.addWeighted(pyr4R, 0.25, pyr3R, 0.25, 0.0, 0.0)\n",
    "    tempPyr = cv2.addWeighted(pyr2R, 0.25, tempPyr, 1.0, 0.0)\n",
    "    descriptor_map = cv2.addWeighted(pyr1, 0.25, tempPyr, 1.0, 0.0)\n",
    "\n",
    "    # Resize the descriptor map to the original size only the output image\n",
    "    descriptor_map = cv2.resize(descriptor_map, (pyr1.shape[1]*bSize, pyr1.shape[0]*bSize), interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    return descriptor_map\n",
    "\n",
    "\n",
    "def compute_local_descriptor(pyr1, pyr2, pyr3, pyr4, bSize=block_size):\n",
    "    \"\"\"\n",
    "    Compute block-wise local descriptors for the pyramids.\n",
    "\n",
    "    Args:\n",
    "        pyr1, pyr2, pyr3, pyr4 (np.ndarray): The input pyramids.\n",
    "        bSize (int): Block size for initial resizing.\n",
    "\n",
    "    Returns:\n",
    "        descriptor_map (np.ndarray): The final blended descriptor map.\n",
    "    \"\"\"\n",
    "    # Process the pyramid levels\n",
    "    descriptor_map = process_pyramid_levels(pyr1, pyr2, pyr3, pyr4)\n",
    "    \n",
    "    return descriptor_map.astype(np.uint8)\n",
    "\n",
    "\n",
    "def compute_global_descriptor(pyr1, pyr2, pyr3, pyr4, bSize=block_size): \n",
    "    \"\"\"\n",
    "    Compute global descriptors for the pyramids using local pixel deviation analysis.\n",
    "\n",
    "    Args:\n",
    "        pyr1, pyr2, pyr3, pyr4 (np.ndarray): The input pyramids.\n",
    "        bSize (int): Block size for initial resizing.\n",
    "\n",
    "    Returns:\n",
    "        descriptor_map (np.ndarray): The final blended global descriptor map.\n",
    "    \"\"\"\n",
    "    def compute_global_img(featureImg):\n",
    "        \"\"\"\n",
    "        Compute global descriptor image using local pixel deviation analysis.\n",
    "        \"\"\"\n",
    "        def local_mean_deviation(window):\n",
    "            \"\"\"\n",
    "            Compute the mean absolute deviation from the center pixel of the window.\n",
    "            \"\"\"\n",
    "            center_pixel = window[len(window) // 2]\n",
    "            return np.mean(np.abs(window - center_pixel))\n",
    "        \n",
    "        # Define a 5x5 or any other size neighborhood\n",
    "        footprint = np.ones((5, 5))\n",
    "        \n",
    "        # Apply the local deviation computation over the image\n",
    "        globalImg = generic_filter(featureImg.astype(np.float32), local_mean_deviation, footprint=footprint)\n",
    "        \n",
    "        # Normalize the image to 0-255\n",
    "        globalImg = (globalImg / globalImg.max()) * 255\n",
    "\n",
    "        return globalImg\n",
    "    \n",
    "    # Apply the optimized global descriptor calculation to each pyramid\n",
    "    pyr1 = compute_global_img(pyr1)\n",
    "    pyr2 = compute_global_img(pyr2)\n",
    "    pyr3 = compute_global_img(pyr3)\n",
    "    pyr4 = compute_global_img(pyr4)\n",
    "    \n",
    "    # Process the pyramid levels\n",
    "    descriptor_map = process_pyramid_levels(pyr1, pyr2, pyr3, pyr4)\n",
    "    \n",
    "    return descriptor_map.astype(np.uint8)\n",
    "\n",
    "def compute_window_descriptor(pyr1, pyr2, pyr3, pyr4, bSize=block_size): \n",
    "    \"\"\"\n",
    "    Compute global descriptors for the pyramids using window-based method.\n",
    "\n",
    "    Args:\n",
    "        pyr1, pyr2, pyr3, pyr4 (np.ndarray): The input pyramids.\n",
    "        bSize (int): Block size for initial resizing.\n",
    "\n",
    "    Returns:\n",
    "        descriptor_map (np.ndarray): The final blended global descriptor map.\n",
    "    \"\"\"\n",
    "    def kmCSMC(featureImg):\n",
    "        \"\"\"\n",
    "        Compute global descriptor image using window-based method (using kernel approach as an optimisation).\n",
    "        \"\"\"\n",
    "        x, y = featureImg.shape\n",
    "        csImg = np.zeros((x, y))\n",
    "\n",
    "        # Create coordinate grids to compute window sizes dynamically\n",
    "        i_grid, j_grid = np.meshgrid(np.arange(x), np.arange(y), indexing='ij')\n",
    "\n",
    "        # Compute dynamic window sizes efficiently\n",
    "        windowSizeX = np.minimum(i_grid, x - i_grid - 1)\n",
    "        windowSizeY = np.minimum(j_grid, y - j_grid - 1)\n",
    "\n",
    "        for i in range(x):\n",
    "            for j in range(y):\n",
    "                # Extract dynamic window\n",
    "                i_min, i_max = i - windowSizeX[i, j], i + windowSizeX[i, j] + 1\n",
    "                j_min, j_max = j - windowSizeY[i, j], j + windowSizeY[i, j] + 1\n",
    "                window = featureImg[i_min:i_max, j_min:j_max]\n",
    "\n",
    "                # Compute mean absolute difference\n",
    "                csImg[i, j] = np.mean(np.abs(window - featureImg[i, j]))\n",
    "\n",
    "        # Normalize to [0, 255]\n",
    "        csImg = (csImg / csImg.max()) * 255\n",
    "\n",
    "        return csImg\n",
    "    \n",
    "    pyr1 = kmCSMC(pyr1)\n",
    "    pyr2 = kmCSMC(pyr2)\n",
    "    pyr3 = kmCSMC(pyr3)\n",
    "    pyr4 = kmCSMC(pyr4)\n",
    "    \n",
    "    # Process the pyramid levels\n",
    "    descriptor_map = process_pyramid_levels(pyr1, pyr2, pyr3, pyr4)\n",
    "    \n",
    "    return descriptor_map.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Binary Pattern (LBP) Texture Map Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import local_binary_pattern\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "def generate_texture_maps(yolo_dataset_path, output_base_path, images_path='images', radius=3, n_points=24):\n",
    "    \"\"\"\n",
    "    Generate and save texture maps using Local Binary Patterns (LBP) for a YOLO dataset.\n",
    "\n",
    "    Args:\n",
    "        yolo_dataset_path (str): Path to the dataset with train, test, valid folders.\n",
    "        output_base_path (str): Path to save the texture maps.\n",
    "        images_path (str): Path within each subset for the images.\n",
    "        radius (int): Radius of the LBP pattern.\n",
    "        n_points (int): Number of points in the LBP pattern.\n",
    "    \"\"\"\n",
    "    for subset in [\"train\", \"test\", \"valid\"]:\n",
    "        input_folder = os.path.join(yolo_dataset_path, subset, images_path)\n",
    "        output_folder = os.path.join(output_base_path, subset, \"LBP_Texture_Maps\")\n",
    "\n",
    "        # Check if input folder exists\n",
    "        if not os.path.exists(input_folder):\n",
    "            print(f\"Skipping {subset} as directory {input_folder} does not exist.\")\n",
    "            continue\n",
    "\n",
    "        # Create the output folder if it doesn't exist\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        # Create the local descriptor folder if it doesn't exist\n",
    "        local_dir=os.path.join(output_folder+\"_local\")\n",
    "        os.makedirs(local_dir, exist_ok=True)\n",
    "\n",
    "        # Create the global descriptor folder if it doesn't exist\n",
    "        global_dir=os.path.join(output_folder+\"_global\")\n",
    "        os.makedirs(global_dir, exist_ok=True)\n",
    "\n",
    "        # Create the window descriptor folder if it doesn't exist\n",
    "        # window_dir=os.path.join(output_folder+\"_window\")\n",
    "        # os.makedirs(window_dir, exist_ok=True)\n",
    "\n",
    "        for image_file in os.listdir(input_folder):\n",
    "            # Process only image files\n",
    "            if image_file.endswith(('.jpg', '.png', '.jpeg')):\n",
    "                image_path = os.path.join(input_folder, image_file)\n",
    "                output_image_path = os.path.join(output_folder, image_file)\n",
    "\n",
    "                # Read the image\n",
    "                image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "                if image is None:\n",
    "                    print(f\"Could not read image {image_path}\")\n",
    "                    continue\n",
    "\n",
    "                # Compute the LBP texture map\n",
    "                try:\n",
    "                    lbp = local_binary_pattern(image, n_points, radius, method='uniform')\n",
    "                    processed_image = (lbp / lbp.max() * 255).astype(np.uint8)  # Normalize to 8-bit image\n",
    "\n",
    "                    # Generate pyramids\n",
    "                    pyr1, pyr2, pyr3, pyr4 = generate_pyramids(processed_image)\n",
    "\n",
    "                    # Compute the local descriptor map\n",
    "                    local_descriptor_map = compute_local_descriptor(pyr1, pyr2, pyr3, pyr4)\n",
    "\n",
    "                    # Compute the global descriptor map\n",
    "                    global_descriptor_map = compute_global_descriptor(pyr1, pyr2, pyr3, pyr4)\n",
    "\n",
    "                    # Compute the window descriptor map\n",
    "                    # window_descriptor_map = compute_window_descriptor(pyr1, pyr2, pyr3, pyr4)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error generating texture map for {image_path}: {e}\")\n",
    "                    continue\n",
    "\n",
    "                # Save the processed image\n",
    "                cv2.imwrite(output_image_path, processed_image)\n",
    "                # Save the local descriptor map\n",
    "                cv2.imwrite(os.path.join(local_dir, image_file), local_descriptor_map)\n",
    "                # Save the global descriptor map\n",
    "                cv2.imwrite(os.path.join(global_dir, image_file), global_descriptor_map)\n",
    "                # Save the window descriptor map\n",
    "                # cv2.imwrite(os.path.join(window_dir, image_file), window_descriptor_map)\n",
    "\n",
    "                print(f\"Saved texture map image to {output_image_path}\")\n",
    "\n",
    "# Generate texture maps\n",
    "generate_texture_maps(yolo_dataset_path, output_base_path, images_path)\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "# Save the duration to a file\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "with open(\"results/texture_map_generation.txt\", \"w\") as f:\n",
    "    f.write(f\"Duration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Canny Edge Detection Map Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "def generate_edge_maps(yolo_dataset_path, output_base_path, images_path='images', low_threshold=50, high_threshold=150):\n",
    "    \"\"\"\n",
    "    Generate and save edge maps using Canny Edge Detection for a YOLO dataset.\n",
    "\n",
    "    Args:\n",
    "        yolo_dataset_path (str): Path to the dataset with train, test, valid folders.\n",
    "        output_base_path (str): Path to save the edge maps.\n",
    "        images_path (str): Path within each subset for the images.\n",
    "        low_threshold (int): Lower threshold for Canny edge detection.\n",
    "        high_threshold (int): Upper threshold for Canny edge detection.\n",
    "    \"\"\"\n",
    "    for subset in [\"train\", \"test\", \"valid\"]:\n",
    "        input_folder = os.path.join(yolo_dataset_path, subset, images_path)\n",
    "        output_folder = os.path.join(output_base_path, subset, \"Canny_Edge_Maps\")\n",
    "\n",
    "        # Check if input folder exists\n",
    "        if not os.path.exists(input_folder):\n",
    "            print(f\"Skipping {subset} as directory {input_folder} does not exist.\")\n",
    "            continue\n",
    "\n",
    "        # Create the output folder if it doesn't exist\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        # Create the local descriptor folder if it doesn't exist\n",
    "        local_dir=os.path.join(output_folder+\"_local\")\n",
    "        os.makedirs(local_dir, exist_ok=True)\n",
    "\n",
    "        # Create the global descriptor folder if it doesn't exist\n",
    "        global_dir=os.path.join(output_folder+\"_global\")\n",
    "        os.makedirs(global_dir, exist_ok=True)\n",
    "\n",
    "        # Create the window descriptor folder if it doesn't exist\n",
    "        # window_dir=os.path.join(output_folder+\"_window\")\n",
    "        # os.makedirs(window_dir, exist_ok=True)\n",
    "\n",
    "        for image_file in os.listdir(input_folder):\n",
    "            # Process only image files\n",
    "            if image_file.endswith(('.jpg', '.png', '.jpeg')):\n",
    "                image_path = os.path.join(input_folder, image_file)\n",
    "                output_image_path = os.path.join(output_folder, image_file)\n",
    "\n",
    "                # Read the image\n",
    "                image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "                if image is None:\n",
    "                    print(f\"Could not read image {image_path}\")\n",
    "                    continue\n",
    "\n",
    "                # Compute the Canny edge map\n",
    "                try:\n",
    "                    edges = cv2.Canny(image, low_threshold, high_threshold)\n",
    "\n",
    "                    # Generate pyramids\n",
    "                    pyr1, pyr2, pyr3, pyr4 = generate_pyramids(edges)\n",
    "\n",
    "                    # Compute the local descriptor map\n",
    "                    local_descriptor_map = compute_local_descriptor(pyr1, pyr2, pyr3, pyr4)\n",
    "\n",
    "                    # Compute the global descriptor map\n",
    "                    global_descriptor_map = compute_global_descriptor(pyr1, pyr2, pyr3, pyr4)\n",
    "\n",
    "                    # Compute the window descriptor map\n",
    "                    # window_descriptor_map = compute_window_descriptor(pyr1, pyr2, pyr3, pyr4)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error generating edge map for {image_path}: {e}\")\n",
    "                    continue\n",
    "\n",
    "                # Save the processed image\n",
    "                cv2.imwrite(output_image_path, edges)\n",
    "                # Save the local descriptor map\n",
    "                cv2.imwrite(os.path.join(local_dir, image_file), local_descriptor_map)\n",
    "                # Save the global descriptor map\n",
    "                cv2.imwrite(os.path.join(global_dir, image_file), global_descriptor_map)\n",
    "                # Save the window descriptor map\n",
    "                # cv2.imwrite(os.path.join(window_dir, image_file), window_descriptor_map)\n",
    "                \n",
    "                print(f\"Saved edge map image to {output_image_path}\")\n",
    "\n",
    "# Generate edge maps\n",
    "generate_edge_maps(yolo_dataset_path, output_base_path, images_path)\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "# Save the duration to a file\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "with open(\"results/canny_edge_map_generation.txt\", \"w\") as f:\n",
    "    f.write(f\"Duration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corner Harris Edge Detection Map Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "def generate_corner_maps(yolo_dataset_path, output_base_path, images_path='images', block_size=2, ksize=3, k=0.04, threshold_ratio=0.02):\n",
    "    \"\"\"\n",
    "    Generate and save corner maps using Harris Corner Detection for a YOLO dataset.\n",
    "\n",
    "    Args:\n",
    "        yolo_dataset_path (str): Path to the dataset with train, test, valid folders.\n",
    "        output_base_path (str): Path to save the corner maps.\n",
    "        images_path (str): Path within each subset for the images.\n",
    "        block_size (int): Neighborhood size for Harris Corner Detection.\n",
    "        ksize (int): Aperture size for Sobel operator.\n",
    "        k (float): Harris detector free parameter.\n",
    "        threshold_ratio (float): Ratio of max corner response to consider as a strong corner.\n",
    "    \"\"\"\n",
    "    for subset in [\"train\", \"test\", \"valid\"]:\n",
    "        input_folder = os.path.join(yolo_dataset_path, subset, images_path)\n",
    "        output_folder = os.path.join(output_base_path, subset, \"Harris_Corner_Maps\")\n",
    "\n",
    "        if not os.path.exists(input_folder):\n",
    "            print(f\"Skipping {subset} as directory {input_folder} does not exist.\")\n",
    "            continue\n",
    "        \n",
    "        # Create the output folder if it doesn't exist\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        # Create the local descriptor folder if it doesn't exist\n",
    "        local_dir=os.path.join(output_folder+\"_local\")\n",
    "        os.makedirs(local_dir, exist_ok=True)\n",
    "\n",
    "        # Create the global descriptor folder if it doesn't exist\n",
    "        global_dir=os.path.join(output_folder+\"_global\")\n",
    "        os.makedirs(global_dir, exist_ok=True)\n",
    "\n",
    "        # Create the window descriptor folder if it doesn't exist\n",
    "        # window_dir=os.path.join(output_folder+\"_window\")\n",
    "        # os.makedirs(window_dir, exist_ok=True)\n",
    "\n",
    "        for image_file in os.listdir(input_folder):\n",
    "            if image_file.endswith(('.jpg', '.png', '.jpeg')):\n",
    "                image_path = os.path.join(input_folder, image_file)\n",
    "                output_image_path = os.path.join(output_folder, image_file)\n",
    "\n",
    "                # Read the image\n",
    "                image = cv2.imread(image_path)\n",
    "                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                if gray is None:\n",
    "                    print(f\"Could not read image {image_path}\")\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    # Compute Harris corner response\n",
    "                    corners = cv2.cornerHarris(gray, block_size, ksize, k)\n",
    "\n",
    "                    # Normalize and threshold\n",
    "                    corners = cv2.dilate(corners, None)  # Dilate for better visualization\n",
    "                    threshold = threshold_ratio * corners.max()\n",
    "                    corner_map = np.zeros_like(gray)\n",
    "\n",
    "                    # Mark strong corners\n",
    "                    corner_map[corners > threshold] = 255\n",
    "\n",
    "                    # Overlay corners on original image for better visualization\n",
    "                    overlay = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n",
    "                    overlay = np.zeros_like(image)\n",
    "                    overlay[corner_map == 255] = [0, 0, 255]  # Mark corners in red\n",
    "\n",
    "                    #  Change to Gray\n",
    "                    overlay = cv2.cvtColor(overlay, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                    # Generate pyramids\n",
    "                    pyr1, pyr2, pyr3, pyr4 = generate_pyramids(overlay)\n",
    "\n",
    "                    # Compute the local descriptor map\n",
    "                    local_descriptor_map = compute_local_descriptor(pyr1, pyr2, pyr3, pyr4)\n",
    "\n",
    "                    # Compute the global descriptor map\n",
    "                    global_descriptor_map = compute_global_descriptor(pyr1, pyr2, pyr3, pyr4)\n",
    "\n",
    "                    # Compute the window descriptor map\n",
    "                    # window_descriptor_map = compute_window_descriptor(pyr1, pyr2, pyr3, pyr4)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error generating corner map for {image_path}: {e}\")\n",
    "                    continue\n",
    "                \n",
    "                # Save the processed image\n",
    "                cv2.imwrite(output_image_path, overlay)\n",
    "                # Save the local descriptor map\n",
    "                cv2.imwrite(os.path.join(local_dir, image_file), local_descriptor_map)\n",
    "                # Save the global descriptor map\n",
    "                cv2.imwrite(os.path.join(global_dir, image_file), global_descriptor_map)\n",
    "                # Save the window descriptor map\n",
    "                # cv2.imwrite(os.path.join(window_dir, image_file), window_descriptor_map)\n",
    "                \n",
    "                print(f\"Saved corner map image to {output_image_path}\")\n",
    "\n",
    "# Generate corner maps\n",
    "generate_corner_maps(yolo_dataset_path, output_base_path, images_path)\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "# Save the duration to a file\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "with open(\"results/harris_corner_map_generation.txt\", \"w\") as f:\n",
    "    f.write(f\"Duration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy Map Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from skimage.filters.rank import entropy\n",
    "from skimage.morphology import disk\n",
    "from skimage.util import img_as_ubyte\n",
    "\n",
    "def generate_entropy_maps(yolo_dataset_path, output_base_path, images_path='images', disk_size=5):\n",
    "    \"\"\"\n",
    "    Generate and save entropy maps for a YOLO dataset.\n",
    "\n",
    "    Args:\n",
    "        yolo_dataset_path (str): Path to the dataset with train, test, valid folders.\n",
    "        output_base_path (str): Path to save the entropy maps.\n",
    "        images_path (str): Path within each subset for the images.\n",
    "        disk_size (int): Size of the structuring element used in entropy calculation.\n",
    "    \"\"\"\n",
    "    for subset in [\"train\", \"test\", \"valid\"]:\n",
    "        input_folder = os.path.join(yolo_dataset_path, subset, images_path)\n",
    "        output_folder = os.path.join(output_base_path, subset, \"Entropy_Maps\")\n",
    "\n",
    "        if not os.path.exists(input_folder):\n",
    "            print(f\"Skipping {subset} as directory {input_folder} does not exist.\")\n",
    "            continue\n",
    "        \n",
    "        # Create the output folder if it doesn't exist\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        # Create the local descriptor folder if it doesn't exist\n",
    "        local_dir=os.path.join(output_folder+\"_local\")\n",
    "        os.makedirs(local_dir, exist_ok=True)\n",
    "\n",
    "        # Create the global descriptor folder if it doesn't exist\n",
    "        global_dir=os.path.join(output_folder+\"_global\")\n",
    "        os.makedirs(global_dir, exist_ok=True)\n",
    "\n",
    "        # Create the window descriptor folder if it doesn't exist\n",
    "        # window_dir=os.path.join(output_folder+\"_window\")\n",
    "        # os.makedirs(window_dir, exist_ok=True)\n",
    "\n",
    "        for image_file in os.listdir(input_folder):\n",
    "            if image_file.endswith(('.jpg', '.png', '.jpeg')):\n",
    "                image_path = os.path.join(input_folder, image_file)\n",
    "                output_image_path = os.path.join(output_folder, image_file)\n",
    "\n",
    "                # Read the image\n",
    "                image = cv2.imread(image_path)\n",
    "                if image is None:\n",
    "                    print(f\"Could not read image {image_path}\")\n",
    "                    continue\n",
    "                \n",
    "                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "                try:\n",
    "                    # Compute entropy map\n",
    "                    entropy_map = entropy(img_as_ubyte(gray), disk(disk_size))\n",
    "\n",
    "                    # Normalize the entropy map to range [0, 1]\n",
    "                    entropy_map = (entropy_map - entropy_map.min()) / (entropy_map.max() - entropy_map.min())\n",
    "\n",
    "                    # Convert to 8-bit format\n",
    "                    entropy_map = img_as_ubyte(entropy_map)\n",
    "\n",
    "                    # Generate pyramids\n",
    "                    pyr1, pyr2, pyr3, pyr4 = generate_pyramids(entropy_map)\n",
    "\n",
    "                    # Compute the local descriptor map\n",
    "                    local_descriptor_map = compute_local_descriptor(pyr1, pyr2, pyr3, pyr4)\n",
    "\n",
    "                    # Compute the global descriptor map\n",
    "                    global_descriptor_map = compute_global_descriptor(pyr1, pyr2, pyr3, pyr4)\n",
    "\n",
    "                    # Compute the window descriptor map\n",
    "                    # window_descriptor_map = compute_window_descriptor(pyr1, pyr2, pyr3, pyr4)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error generating entropy map for {image_path}: {e}\")\n",
    "                    continue\n",
    "                \n",
    "                # Save the processed image\n",
    "                cv2.imwrite(output_image_path, entropy_map)\n",
    "                # Save the local descriptor map\n",
    "                cv2.imwrite(os.path.join(local_dir, image_file), local_descriptor_map)\n",
    "                # Save the global descriptor map\n",
    "                cv2.imwrite(os.path.join(global_dir, image_file), global_descriptor_map)\n",
    "                # Save the window descriptor map\n",
    "                # cv2.imwrite(os.path.join(window_dir, image_file), window_descriptor_map)\n",
    "                \n",
    "                print(f\"Saved entropy map image to {output_image_path}\")\n",
    "\n",
    "# Measure execution time\n",
    "start_time = time.time()\n",
    "generate_entropy_maps(yolo_dataset_path, output_base_path, images_path)\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "\n",
    "# Save the duration to a file\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "with open(\"results/entropy_map_generation.txt\", \"w\") as f:\n",
    "    f.write(f\"Duration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bounding Box Overlay on Grayscale Image Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Constant to adjust the box shading difference\n",
    "deduct_constant = int(200 / number_of_classes) # 200 is the maximum value for the box shade\n",
    "\n",
    "def process_images_with_annotations(yolo_dataset_path, output_base_path, images_path='images'):\n",
    "    \"\"\"\n",
    "    Convert images to grayscale, overlay thick bounding boxes from _annotations.coco.json,\n",
    "    darken the background outside the boxes while preserving intensity variations,\n",
    "    and save the processed images in single-channel grayscale format.\n",
    "\n",
    "    Transformations:\n",
    "    - Convert to grayscale\n",
    "    - Darken (intensities of pixels) the background outside the bounding boxes\n",
    "    - Overlay thick bounding boxes with white outlines\n",
    "    - For multi-class object detection, the color of the box is different for each class\n",
    "    - For binary classification, the color of the box is the same for both classes\n",
    "\n",
    "    Based of/ inspired from:\n",
    "    - An omniscient teacher which has the answer sheet of what the solutions for the exam are\n",
    "    - A student who has the question paper and is seeking help from the teacher must assume that the teacher knows the answer\n",
    "     \n",
    "    Args:\n",
    "        yolo_dataset_path (str): Path to the dataset containing train, test, valid folders.\n",
    "        output_base_path (str): Path to save the processed images.\n",
    "        images_path (str): Path within each subset for the images.\n",
    "    \"\"\"\n",
    "    for subset in [\"train\", \"test\", \"valid\"]:\n",
    "        input_folder = os.path.join(yolo_dataset_path, subset, images_path)\n",
    "        annotation_file = os.path.join(yolo_dataset_path, subset, \"_annotations.coco.json\")\n",
    "        output_folder = os.path.join(output_base_path, subset, \"Overlay_Box\")\n",
    "        \n",
    "        if not os.path.exists(input_folder) or not os.path.exists(annotation_file):\n",
    "            print(f\"Skipping {subset} as required files are missing.\")\n",
    "            continue\n",
    "        \n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        \n",
    "        # Load COCO annotations\n",
    "        with open(annotation_file, 'r') as f:\n",
    "            annotations = json.load(f)\n",
    "        \n",
    "        images_info = {img['id']: img['file_name'] for img in annotations['images']}\n",
    "        \n",
    "        # Group annotations by image ID\n",
    "        annotations_by_image = {}\n",
    "        for ann in annotations['annotations']:\n",
    "            img_id = ann['image_id']\n",
    "            bbox = ann['bbox']  # [x, y, width, height]\n",
    "            category_id = ann['category_id']\n",
    "            if img_id not in annotations_by_image:\n",
    "                annotations_by_image[img_id] = []\n",
    "            annotations_by_image[img_id].append((bbox, category_id))\n",
    "        \n",
    "        for img_id, img_file in images_info.items():\n",
    "            image_path = os.path.join(input_folder, img_file)\n",
    "            output_image_path = os.path.join(output_folder, img_file)\n",
    "            \n",
    "            # Read image\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                print(f\"Could not read image {image_path}\")\n",
    "                continue\n",
    "            \n",
    "            # Convert to grayscale\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Darken the background while maintaining intensity variations\n",
    "            darkened_gray = (gray * 0.3).astype(np.uint8)  # Reduce intensity by 30%, before was 50%\n",
    "            processed_image = darkened_gray.copy()\n",
    "            \n",
    "            # Overlay bounding boxes with a bright white overlay\n",
    "            if img_id in annotations_by_image:\n",
    "                # Sort annotations by iamge by largest to smallest area (Added later can be removed if code is breaking)\n",
    "                annotations_by_image[img_id].sort(key=lambda x: x[0][2] * x[0][3], reverse=True)\n",
    "\n",
    "                for bbox, category_id in annotations_by_image[img_id]:\n",
    "                    \"\"\"\n",
    "                        Calculating the Deduct Amount for the box color, to differentiate the different object types\n",
    "                        The Deduct Amount is calculated by multiplying the deduct constant with the category_id\n",
    "\n",
    "                        Set deduct_box_color to 0 for binary classification\n",
    "                    \"\"\"\n",
    "                    deduct_box_color = category_id * deduct_constant\n",
    "\n",
    "                    x, y, w, h = map(int, bbox)\n",
    "                    processed_image[y:y+h, x:x+w] = gray[y:y+h, x:x+w]  # Restore original intensity inside boxes\n",
    "                    cv2.rectangle(processed_image, (x, y), (x + w, y + h), (255 - deduct_box_color,), thickness=7)  # Thick white outline\n",
    "                    white_box = processed_image.copy()\n",
    "                    cv2.rectangle(white_box, (x, y), (x + w, y + h), (255 - deduct_box_color,), thickness=-1)  # White overlay inside box with transparency\n",
    "                    # Blend the white overlay with the original image\n",
    "                    processed_image = cv2.addWeighted(processed_image, 0.7, white_box, 0.3, 0)\n",
    "            \n",
    "            # Save processed image\n",
    "            cv2.imwrite(output_image_path, processed_image)\n",
    "            print(f\"Processed and saved: {output_image_path}\")\n",
    "\n",
    "\n",
    "# Measure execution time\n",
    "start_time = time.time()\n",
    "process_images_with_annotations(yolo_dataset_path, output_base_path)\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "\n",
    "# Save the duration to a file\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "with open(\"results/overlay_box_generation.txt\", \"w\") as f:\n",
    "    f.write(f\"Duration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bounding Box Mask Image Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Constant to adjust the box shading difference\n",
    "deduct_constant = int(200 / number_of_classes) # 200 is the maximum value for the box shade\n",
    "\n",
    "def process_images_with_annotations(yolo_dataset_path, output_base_path, images_path='images'):\n",
    "    \"\"\"\n",
    "    Convert images to grayscale, overlay thick bounding boxes with different shades, \n",
    "    and set the background to black while maintaining intensity variations inside boxes.\n",
    "    \n",
    "    Args:\n",
    "        yolo_dataset_path (str): Path to the dataset containing train, test, valid folders.\n",
    "        output_base_path (str): Path to save the processed images.\n",
    "        images_path (str): Path within each subset for the images.\n",
    "    \"\"\"\n",
    "    for subset in [\"train\", \"test\", \"valid\"]:\n",
    "        input_folder = os.path.join(yolo_dataset_path, subset, images_path)\n",
    "        annotation_file = os.path.join(yolo_dataset_path, subset, \"_annotations.coco.json\")\n",
    "        output_folder = os.path.join(output_base_path, subset, \"Box_Mask\")\n",
    "        \n",
    "        if not os.path.exists(input_folder) or not os.path.exists(annotation_file):\n",
    "            print(f\"Skipping {subset} as required files are missing.\")\n",
    "            continue\n",
    "        \n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        \n",
    "        # Load COCO annotations\n",
    "        with open(annotation_file, 'r') as f:\n",
    "            annotations = json.load(f)\n",
    "        \n",
    "        images_info = {img['id']: img['file_name'] for img in annotations['images']}\n",
    "        \n",
    "        # Group annotations by image ID\n",
    "        annotations_by_image = {}\n",
    "        for ann in annotations['annotations']:\n",
    "            img_id = ann['image_id']\n",
    "            bbox = ann['bbox']  # [x, y, width, height]\n",
    "            category_id = ann['category_id']\n",
    "            if img_id not in annotations_by_image:\n",
    "                annotations_by_image[img_id] = []\n",
    "            annotations_by_image[img_id].append((bbox, category_id))\n",
    "        \n",
    "        for img_id, img_file in images_info.items():\n",
    "            image_path = os.path.join(input_folder, img_file)\n",
    "            output_image_path = os.path.join(output_folder, img_file)\n",
    "            \n",
    "            # Read image\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                print(f\"Could not read image {image_path}\")\n",
    "                continue\n",
    "            \n",
    "            # Convert to grayscale and set background to black\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            processed_image = np.zeros_like(gray)  # Start with black background\n",
    "            \n",
    "            # Overlay bounding boxes with different shades\n",
    "            if img_id in annotations_by_image:\n",
    "\n",
    "                # Sort annotations by iamge by largest to smallest area (Added later can be removed if code is breaking)\n",
    "                annotations_by_image[img_id].sort(key=lambda x: x[0][2] * x[0][3], reverse=True)\n",
    "\n",
    "                for bbox, category_id in annotations_by_image[img_id]:\n",
    "                    # Calculate shading based on category ID\n",
    "                    box_shade = 255 - (category_id * deduct_constant)\n",
    "                    box_shade = max(50, box_shade)  # Prevents box from being too dark\n",
    "                    \n",
    "                    x, y, w, h = map(int, bbox)\n",
    "                    processed_image[y:y+h, x:x+w] = box_shade  # Apply box_shade inside boxes\n",
    "                    cv2.rectangle(processed_image, (x, y), (x + w, y + h), (box_shade,), thickness=7)  # Draw box\n",
    "            \n",
    "            # Save processed image\n",
    "            cv2.imwrite(output_image_path, processed_image)\n",
    "            print(f\"Processed and saved: {output_image_path}\")\n",
    "\n",
    "# Measure execution time\n",
    "start_time = time.time()\n",
    "process_images_with_annotations(yolo_dataset_path, output_base_path)\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "\n",
    "# Save execution duration to a file\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "with open(\"results/box_mask_generation.txt\", \"w\") as f:\n",
    "    f.write(f\"Duration: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Min-Max Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Privileged Information Directories\n",
    "PRIVILEGED_INFORMATION_DIRS = [\n",
    "    # \"Saliency_itti\", \"Saliency_deepgaze\", \n",
    "    # \"Depth_Depth_Anything\", \"Depth_DPT_Large\",\n",
    "    # \"HoG_Features\",\n",
    "    # \"LBP_Texture_Maps\", \"LBP_Texture_Maps_local\", \"LBP_Texture_Maps_global\",\n",
    "    # \"Canny_Edge_Maps\", \"Canny_Edge_Maps_local\", \"Canny_Edge_Maps_global\",\n",
    "    # \"Harris_Corner_Maps\", \"Harris_Corner_Maps_local\", \"Harris_Corner_Maps_global\",\n",
    "    # \"Entropy_Maps\", \"Entropy_Maps_local\", \"Entropy_Maps_global\",\n",
    "    # \"Overlay_Box\",\n",
    "    \"Box_Mask\"\n",
    "]\n",
    "\n",
    "# Number of input image channels (RGB + Extras)\n",
    "NUM_CHANNELS = 3 + len(PRIVILEGED_INFORMATION_DIRS)\n",
    "\n",
    "# Initialize min and max values\n",
    "min_values = np.full(NUM_CHANNELS, np.inf, dtype=np.float64)\n",
    "max_values = np.full(NUM_CHANNELS, -np.inf, dtype=np.float64)\n",
    "\n",
    "def update_min_max(image, min_values, max_values, channel_idx):\n",
    "    \"\"\"Update min and max values for a given channel.\"\"\"\n",
    "    min_values[channel_idx] = min(min_values[channel_idx], np.min(image))\n",
    "    max_values[channel_idx] = max(max_values[channel_idx], np.max(image))\n",
    "\n",
    "# Process original images\n",
    "for directory in [\"train\", \"valid\", \"test\"]:\n",
    "    image_dir = os.path.join(yolo_dataset_path, directory, images_path)\n",
    "    image_filenames = [f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "    \n",
    "    for image_filename in tqdm(image_filenames, desc=f\"Processing Original Images in {directory}\"):\n",
    "        image_path = os.path.join(image_dir, image_filename)\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED).astype(np.float32)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) if image.shape[-1] == 3 else image\n",
    "        \n",
    "        # Update min and max values\n",
    "        for c in range(3):\n",
    "            update_min_max(image[..., c], min_values, max_values, c)\n",
    "\n",
    "# Process privileged information images\n",
    "for directory in [\"train\", \"valid\", \"test\"]:\n",
    "    for idx, privileged_dir in enumerate(PRIVILEGED_INFORMATION_DIRS):\n",
    "        privileged_image_dir = os.path.join(yolo_dataset_path, directory, privileged_dir)\n",
    "        privileged_image_filenames = [f for f in os.listdir(privileged_image_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "        \n",
    "        for privileged_image_filename in tqdm(privileged_image_filenames, desc=f\"Processing {privileged_dir} in {directory}\"):\n",
    "            privileged_image_path = os.path.join(privileged_image_dir, privileged_image_filename)\n",
    "            privileged_image = cv2.imread(privileged_image_path, cv2.IMREAD_UNCHANGED).astype(np.float32)\n",
    "            privileged_image = np.expand_dims(privileged_image, axis=-1) if len(privileged_image.shape) == 2 else privileged_image\n",
    "            \n",
    "            # Update min and max values\n",
    "            update_min_max(privileged_image, min_values, max_values, idx + 3)\n",
    "\n",
    "# Normalize and overwrite images\n",
    "for directory in [\"train\", \"valid\", \"test\"]:\n",
    "    image_dir = os.path.join(yolo_dataset_path, directory, images_path)\n",
    "    image_filenames = [f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "    \n",
    "    for image_filename in tqdm(image_filenames, desc=f\"Normalizing Original Images in {directory}\"):\n",
    "        image_path = os.path.join(image_dir, image_filename)\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED).astype(np.float32)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) if image.shape[-1] == 3 else image\n",
    "        \n",
    "        # Normalize all RGB channels together\n",
    "        for c in range(3):\n",
    "            image[..., c] = np.clip((image[..., c] - min_values[c]) / (max_values[c] - min_values[c]), 0, 1) if max_values[c] > min_values[c] else 0\n",
    "        image = (image * 255).astype(np.uint8)  # Scale back to [0, 255]\n",
    "\n",
    "        # Saving the image as RGB\n",
    "        cv2.imwrite(image_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "# Normalize and overwrite privileged information images\n",
    "for directory in [\"train\", \"valid\", \"test\"]:\n",
    "    for idx, privileged_dir in enumerate(PRIVILEGED_INFORMATION_DIRS):\n",
    "        privileged_image_dir = os.path.join(yolo_dataset_path, directory, privileged_dir)\n",
    "        privileged_image_filenames = [f for f in os.listdir(privileged_image_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "        \n",
    "        for privileged_image_filename in tqdm(privileged_image_filenames, desc=f\"Normalizing {privileged_dir} in {directory}\"):\n",
    "            privileged_image_path = os.path.join(privileged_image_dir, privileged_image_filename)\n",
    "            privileged_image = cv2.imread(privileged_image_path, cv2.IMREAD_UNCHANGED).astype(np.float32)\n",
    "            privileged_image = np.expand_dims(privileged_image, axis=-1) if len(privileged_image.shape) == 2 else privileged_image\n",
    "            \n",
    "            privileged_image = np.clip((privileged_image - min_values[idx + 3]) / (max_values[idx + 3] - min_values[idx + 3]), 0, 1) if max_values[idx + 3] > min_values[idx + 3] else 0\n",
    "            privileged_image = (privileged_image * 255).astype(np.uint8)\n",
    "\n",
    "            cv2.imwrite(privileged_image_path, privileged_image)\n",
    "\n",
    "# Save min and max values\n",
    "results = {\n",
    "    \"mins\": min_values.tolist(),\n",
    "    \"maxs\": max_values.tolist(),\n",
    "    \"channels\": [\"Red\", \"Green\", \"Blue\"] + PRIVILEGED_INFORMATION_DIRS\n",
    "}\n",
    "\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "with open(\"results/dataset_min_max.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "\n",
    "print(\"Dataset min and max values saved to results/dataset_min_max.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Image Mean and Standard Deviation for the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Privileged Information Directories\n",
    "PRIVILEGED_INFORMATION_DIRS = [\n",
    "    # \"Saliency_itti\", \"Saliency_deepgaze\", \n",
    "    # \"Depth_Depth_Anything\", \"Depth_DPT_Large\",\n",
    "    # \"HoG_Features\",\n",
    "    # \"LBP_Texture_Maps\", \"LBP_Texture_Maps_local\", \"LBP_Texture_Maps_global\",\n",
    "    # \"Canny_Edge_Maps\", \"Canny_Edge_Maps_local\", \"Canny_Edge_Maps_global\",\n",
    "    # \"Harris_Corner_Maps\", \"Harris_Corner_Maps_local\", \"Harris_Corner_Maps_global\",\n",
    "    # \"Entropy_Maps\", \"Entropy_Maps_local\", \"Entropy_Maps_global\",\n",
    "    # \"Overlay_Box\", \n",
    "    \"Box_Mask\"\n",
    "]\n",
    "\n",
    "# Number of input image channels (RGB + Extras)\n",
    "NUM_CHANNELS = 3 + len(PRIVILEGED_INFORMATION_DIRS)\n",
    "\n",
    "# Initialize accumulators for original and privileged channels\n",
    "sum_values = np.zeros(NUM_CHANNELS, dtype=np.float64)\n",
    "sum_squared = np.zeros(NUM_CHANNELS, dtype=np.float64)\n",
    "min_values = np.full(NUM_CHANNELS, np.inf, dtype=np.float64)\n",
    "max_values = np.full(NUM_CHANNELS, -np.inf, dtype=np.float64)\n",
    "pixel_count = 0\n",
    "\n",
    "# Process original images\n",
    "for directory in [\"train\", \"valid\", \"test\"]:\n",
    "    image_dir = os.path.join(yolo_dataset_path, directory, images_path)\n",
    "    image_filenames = [f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "    \n",
    "    for image_filename in tqdm(image_filenames, desc=f\"Processing Original Images in {directory}\"):\n",
    "        image_path = os.path.join(image_dir, image_filename)\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED).astype(np.float32)\n",
    "        # Change to RGB if the image is in BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) if image.shape[-1] == 3 else image\n",
    "\n",
    "        # Update min and max values for each channel\n",
    "        min_values[:3] = np.minimum(min_values[:3], np.min(image, axis=(0, 1)))\n",
    "        max_values[:3] = np.maximum(max_values[:3], np.max(image, axis=(0, 1)))\n",
    "\n",
    "        # Normalize the image by dividing by 255 to be in range [0, 1]\n",
    "        image = image / 255.0\n",
    "\n",
    "        sum_values[:3] += np.sum(image, axis=(0, 1))\n",
    "        sum_squared[:3] += np.sum(image ** 2, axis=(0, 1))\n",
    "        pixel_count += image.shape[0] * image.shape[1]\n",
    "\n",
    "# Process privileged information images\n",
    "for directory in [\"train\", \"valid\", \"test\"]:\n",
    "    for idx, privileged_dir in enumerate(PRIVILEGED_INFORMATION_DIRS):\n",
    "        privileged_image_dir = os.path.join(yolo_dataset_path, directory, privileged_dir)\n",
    "        privileged_image_filenames = [f for f in os.listdir(privileged_image_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "\n",
    "        for privileged_image_filename in tqdm(privileged_image_filenames, desc=f\"Processing {privileged_dir} in {directory}\"):\n",
    "            privileged_image_path = os.path.join(privileged_image_dir, privileged_image_filename)\n",
    "            privileged_image = cv2.imread(privileged_image_path, cv2.IMREAD_UNCHANGED).astype(np.float32)\n",
    "            \n",
    "            # Ensure single-channel images have a channel dimension\n",
    "            if len(privileged_image.shape) == 2:\n",
    "                privileged_image = privileged_image[..., np.newaxis]\n",
    "\n",
    "            privileged_image_min = np.min(privileged_image, axis=(0, 1))\n",
    "            privileged_image_max = np.max(privileged_image, axis=(0, 1))\n",
    "            \n",
    "            # Normalize the image by dividing by 255 to be in range [0, 1]\n",
    "            privileged_image = privileged_image / 255.0\n",
    "\n",
    "            # Update min and max values for privileged channels\n",
    "            min_values[idx + 3] = min(min_values[idx + 3], np.min(privileged_image_min).item())  \n",
    "            max_values[idx + 3] = max(max_values[idx + 3], np.max(privileged_image_max).item())  \n",
    "\n",
    "            sum_values[idx + 3] += np.sum(privileged_image, axis=(0, 1)).item()  \n",
    "            sum_squared[idx + 3] += np.sum(privileged_image ** 2, axis=(0, 1)).item()\n",
    "\n",
    "\n",
    "# Compute per-channel mean, std, min, and max\n",
    "image_means = (sum_values / pixel_count).tolist()\n",
    "image_stds = (np.sqrt((sum_squared / pixel_count) - (np.array(image_means) ** 2))).tolist()\n",
    "min_values = min_values.tolist()\n",
    "max_values = max_values.tolist()\n",
    "\n",
    "# round to 3 decimal places\n",
    "image_means = [round(mean, 3) for mean in image_means]\n",
    "image_stds = [round(std, 3) for std in image_stds]\n",
    "\n",
    "# Save results to JSON\n",
    "results = {\n",
    "    \"means\": image_means,\n",
    "    \"stds\": image_stds,\n",
    "    \"mins\": min_values,\n",
    "    \"maxs\": max_values,\n",
    "    \"channels\": [\"Red\", \"Green\", \"Blue\"] + PRIVILEGED_INFORMATION_DIRS\n",
    "}\n",
    "\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "with open(\"results/dataset_means_and_stds.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "\n",
    "print(\"Dataset means, standard deviations, mins, and maxs saved to results/dataset_means_and_stds.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the dataset means and standard deviations\n",
    "with open(\"results/dataset_min_max.json\", \"r\") as f:\n",
    "    dataset_stats = json.load(f)\n",
    "\n",
    "# Create a DataFrame from the dataset statistics\n",
    "df1 = pd.DataFrame(dataset_stats).set_index(\"channels\")\n",
    "\n",
    "# Display the DataFrame\n",
    "display(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the dataset means and standard deviations\n",
    "with open(\"results/dataset_means_and_stds.json\", \"r\") as f:\n",
    "    dataset_stats = json.load(f)\n",
    "\n",
    "# Create a DataFrame from the dataset statistics\n",
    "df2 = pd.DataFrame(dataset_stats).set_index(\"channels\")\n",
    "\n",
    "# Display the DataFrame\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Displaying the Generated Privileged Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def choose_random_image_from_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Choose a random image from the specified folder.\n",
    "    Args:\n",
    "        folder_path (str): Path to the folder containing images.\n",
    "    \"\"\"\n",
    "    # Get a list of all image files in the folder\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "    \n",
    "    if not image_files:\n",
    "        print(f\"No image files found in {folder_path}.\")\n",
    "        return\n",
    "    \n",
    "    # Choose a random image from the list\n",
    "    random_image = random.choice(image_files)\n",
    "    \n",
    "    # Full path to the random image\n",
    "    random_image_path = os.path.join(folder_path, random_image)\n",
    "    \n",
    "    print(f\"Randomly selected image: {random_image_path}\")\n",
    "    return random_image, random_image_path\n",
    "\n",
    "def plot_image_with_privileged_info(image_paths_with_info):\n",
    "    \"\"\"Plot multiple images with different colormaps and add a suptitle.\"\"\"\n",
    "    columns = 5\n",
    "    rows = (len(image_paths_with_info) + columns - 1) // columns  # Compute rows\n",
    "\n",
    "    plt.figure(figsize=(25, rows * 5))\n",
    "    plt.suptitle(\"Image with Privileged Information\", fontsize=25)\n",
    "\n",
    "    for idx, img_info in enumerate(image_paths_with_info):\n",
    "        image_path = img_info['image_path']\n",
    "        title = img_info['title']\n",
    "        cmap = img_info['cmap']\n",
    "\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "        if image is None:\n",
    "            print(f\"Error loading image {image_path}.\")\n",
    "            continue\n",
    "\n",
    "        if len(image.shape) == 3 and image.shape[2] == 3:  # Convert BGR to RGB if needed\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Normalise image via min-max scaling\n",
    "        image = (image - np.min(image)) / (np.max(image) - np.min(image) + 1e-8)\n",
    "\n",
    "        plt.subplot(rows, columns, idx + 1)\n",
    "        plt.imshow(image, cmap=cmap)\n",
    "        plt.title(title, fontsize=18)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.2, hspace=0.02)  # Reduce space between subplots\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage: specify the path to your 'combined_images' and 'edge_images' folder\n",
    "images_folder = '../datasets/01m-All-1/train/images'  # Replace with actual path\n",
    "Itti_images_folder = '../datasets/01m-All-1/train/Saliency_itti'  # Replace with actual path\n",
    "Deepgaze_images_folder = '../datasets/01m-All-1/train/Saliency_deepgaze'  # Replace with actual path\n",
    "Depth_Anything_images_folder = '../datasets/01m-All-1/train/Depth_Depth_Anything'  # Replace with actual path\n",
    "Dpt_Large_images_folder = '../datasets/01m-All-1/train/Depth_DPT_Large'  # Replace with actual path\n",
    "\n",
    "HoG_images_folder = '../datasets/01m-All-1/train/HoG_Features'  # Replace with actual path\n",
    "\n",
    "Lbp_images_folder = '../datasets/01m-All-1/train/LBP_Texture_Maps'  # Replace with actual path\n",
    "Lbp_images_folder_local = '../datasets/01m-All-1/train/LBP_Texture_Maps_local'  # Replace with actual path\n",
    "Lbp_images_folder_global = '../datasets/01m-All-1/train/LBP_Texture_Maps_global'  # Replace with actual path\n",
    "Lbp_images_folder_window = '../datasets/01m-All-1/train/LBP_Texture_Maps_window'  # Replace with actual path\n",
    "\n",
    "Canny_Edge_images_folder = '../datasets/01m-All-1/train/Canny_Edge_Maps'  # Replace with actual path\n",
    "Canny_Edge_images_folder_local = '../datasets/01m-All-1/train/Canny_Edge_Maps_local'  # Replace with actual path\n",
    "Canny_Edge_images_folder_global = '../datasets/01m-All-1/train/Canny_Edge_Maps_global'  # Replace with actual path\n",
    "Canny_Edge_images_folder_window = '../datasets/01m-All-1/train/Canny_Edge_Maps_window'  # Replace with actual path\n",
    "\n",
    "Harris_Corner_images_folder = '../datasets/01m-All-1/train/Harris_Corner_Maps'  # Replace with actual path\n",
    "Harris_Corner_images_folder_local = '../datasets/01m-All-1/train/Harris_Corner_Maps_local'  # Replace with actual path\n",
    "Harris_Corner_images_folder_global = '../datasets/01m-All-1/train/Harris_Corner_Maps_global'  # Replace with actual path\n",
    "Harris_Corner_images_folder_window = '../datasets/01m-All-1/train/Harris_Corner_Maps_window'  # Replace with actual path\n",
    "\n",
    "Entropy_images_folder = '../datasets/01m-All-1/train/Entropy_Maps'  # Replace with actual path\n",
    "Entropy_images_folder_local = '../datasets/01m-All-1/train/Entropy_Maps_local'  # Replace with actual path\n",
    "Entropy_images_folder_global = '../datasets/01m-All-1/train/Entropy_Maps_global'  # Replace with actual path\n",
    "Entropy_images_folder_window = '../datasets/01m-All-1/train/Entropy_Maps_window'  # Replace with actual path\n",
    "\n",
    "Overlay_Box_images_folder = '../datasets/01m-All-1/train/Overlay_Box'  # Replace with actual path\n",
    "Box_Mask_images_folder = '../datasets/01m-All-1/train/Box_Mask'  # Replace with actual path\n",
    "\n",
    "# Choose a random image from the combined images folder\n",
    "random_image_name, random_image_path = choose_random_image_from_folder(images_folder)\n",
    "\n",
    "# Construct the path for the corresponding image in each folder\n",
    "itti_image_path = os.path.join(Itti_images_folder, random_image_name)\n",
    "deepgaze_image_path = os.path.join(Deepgaze_images_folder, random_image_name)\n",
    "depth_anything_image_path = os.path.join(Depth_Anything_images_folder, random_image_name)\n",
    "dpt_large_image_path = os.path.join(Dpt_Large_images_folder, random_image_name)\n",
    "\n",
    "hog_image_path = os.path.join(HoG_images_folder, random_image_name)\n",
    "\n",
    "lbp_image_path = os.path.join(Lbp_images_folder, random_image_name)\n",
    "lbp_image_path_local = os.path.join(Lbp_images_folder_local, random_image_name)\n",
    "lbp_image_path_global = os.path.join(Lbp_images_folder_global, random_image_name)\n",
    "lbp_image_path_window = os.path.join(Lbp_images_folder_window, random_image_name)\n",
    "\n",
    "canny_edge_image_path = os.path.join(Canny_Edge_images_folder, random_image_name)\n",
    "canny_edge_image_path_local = os.path.join(Canny_Edge_images_folder_local, random_image_name)\n",
    "canny_edge_image_path_global = os.path.join(Canny_Edge_images_folder_global, random_image_name)\n",
    "canny_edge_image_path_window = os.path.join(Canny_Edge_images_folder_window, random_image_name)\n",
    "\n",
    "harris_corner_image_path = os.path.join(Harris_Corner_images_folder, random_image_name)\n",
    "harris_corner_image_path_local = os.path.join(Harris_Corner_images_folder_local, random_image_name)\n",
    "harris_corner_image_path_global = os.path.join(Harris_Corner_images_folder_global, random_image_name)\n",
    "harris_corner_image_path_window = os.path.join(Harris_Corner_images_folder_window, random_image_name)\n",
    "\n",
    "entropy_image_path = os.path.join(Entropy_images_folder, random_image_name)\n",
    "entropy_image_path_local = os.path.join(Entropy_images_folder_local, random_image_name)\n",
    "entropy_image_path_global = os.path.join(Entropy_images_folder_global, random_image_name)\n",
    "entropy_image_path_window = os.path.join(Entropy_images_folder_window, random_image_name)\n",
    "\n",
    "overlay_box_image_path = os.path.join(Overlay_Box_images_folder, random_image_name)\n",
    "box_mask_image_path = os.path.join(Box_Mask_images_folder, random_image_name)\n",
    "\n",
    "# Define a list of image paths with titles and colormap (cmap)\n",
    "images_with_info = [\n",
    "    {'image_path': random_image_path, 'title': 'Original Image (RGB)', 'cmap': 'gray'},\n",
    "    {'image_path': itti_image_path, 'title': 'Itti Saliency Map', 'cmap': 'winter'},\n",
    "    {'image_path': deepgaze_image_path, 'title': 'Deepgaze IIE Saliency Map', 'cmap': 'winter'},\n",
    "    {'image_path': depth_anything_image_path, 'title': 'Depth Anything Depth Map', 'cmap': 'inferno'},\n",
    "    {'image_path': dpt_large_image_path, 'title': 'DPT Large Depth Map', 'cmap': 'inferno'},\n",
    "\n",
    "    {'image_path': hog_image_path, 'title': 'HoG Features', 'cmap': 'viridis'},\n",
    "\n",
    "    {'image_path': lbp_image_path, 'title': 'LBP Texture Map', 'cmap': 'viridis'},\n",
    "    {'image_path': lbp_image_path_local, 'title': 'LBP Local Descriptor Map', 'cmap': 'viridis'},\n",
    "    {'image_path': lbp_image_path_global, 'title': 'LBP Global Descriptor Map', 'cmap': 'viridis'},\n",
    "    # {'image_path': lbp_image_path_window, 'title': 'LBP Window Descriptor Map', 'cmap': 'viridis'},\n",
    "\n",
    "    {'image_path': canny_edge_image_path, 'title': 'Canny Edge Detection Map', 'cmap': 'magma'},\n",
    "    {'image_path': canny_edge_image_path_local, 'title': 'Canny Edge Local Descriptor Map', 'cmap': 'magma'},\n",
    "    {'image_path': canny_edge_image_path_global, 'title': 'Canny Edge Global Descriptor Map', 'cmap': 'magma'},\n",
    "    # {'image_path': canny_edge_image_path_window, 'title': 'Canny Edge Window Descriptor Map', 'cmap': 'magma'},\n",
    "\n",
    "    {'image_path': harris_corner_image_path, 'title': 'Corner Harris Edge Detection Map', 'cmap': 'plasma'},\n",
    "    {'image_path': harris_corner_image_path_local, 'title': 'Corner Harris Local Descriptor Map', 'cmap': 'plasma'},\n",
    "    {'image_path': harris_corner_image_path_global, 'title': 'Corner Harris Global Descriptor Map', 'cmap': 'plasma'},\n",
    "    # {'image_path': harris_corner_image_path_window, 'title': 'Corner Harris Window Descriptor Map', 'cmap': 'plasma'},\n",
    "\n",
    "    {'image_path': entropy_image_path, 'title': 'Entropy Map', 'cmap': 'jet'},\n",
    "    {'image_path': entropy_image_path_local, 'title': 'Entropy Local Descriptor Map', 'cmap': 'jet'},\n",
    "    {'image_path': entropy_image_path_global, 'title': 'Entropy Global Descriptor Map', 'cmap': 'jet'},\n",
    "    # {'image_path': entropy_image_path_window, 'title': 'Entropy Window Descriptor Map', 'cmap': 'jet'},\n",
    "    \n",
    "    {'image_path': overlay_box_image_path, 'title': 'Grayscale Overlay Box Image', 'cmap': 'gray'},\n",
    "    {'image_path': box_mask_image_path, 'title': 'Bounding Box Mask Image', 'cmap': 'gray'},\n",
    "]\n",
    "\n",
    "plot_image_with_privileged_info(images_with_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
